<html><!-- Mirrored from developer.mozilla.org/en-US/docs/Web/API/WebVR_API/Concepts by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 14 Feb 2023 04:50:09 GMT --><!-- Added by HTTrack --><head><meta http-equiv="content-type" content="text/html;charset=utf-8"><!-- /Added by HTTrack -->
<meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" href="../../../../../favicon-48x48.cbbd161b.png"><link rel="apple-touch-icon" href="../../../../../apple-touch-icon.6803c6f0.png"><meta name="theme-color" content="#ffffff"><link rel="manifest" href="../../../../../manifest.56b1cedc.json"><link rel="search" type="application/opensearchdescription+xml" href="https://developer.mozilla.org/opensearch.xml" title="MDN Web Docs"><title>WebVR concepts</title><link rel="alternate" title="WebVR の概要" href="https://developer.mozilla.org/ja/docs/Web/API/WebVR_API/Concepts" hreflang="ja"><link rel="alternate" title="WebVR concepts" href="https://developer.mozilla.org/zh-CN/docs/Web/API/WebVR_API/Concepts" hreflang="zh"><link rel="alternate" title="WebVR concepts" href="Concepts.html" hreflang="en"><meta name="robots" content="index, follow"><meta name="description" content="This article discusses some of the concepts and theory behind virtual reality (VR). If you are a newcomer to the area, it is worthwhile getting an understanding of these topics before you start diving into code."><meta property="og:url" content="Concepts.html"><meta property="og:title" content="WebVR concepts - Web APIs | MDN"><meta property="og:locale" content="en-US"><meta property="og:description" content="This article discusses some of the concepts and theory behind virtual reality (VR). If you are a newcomer to the area, it is worthwhile getting an understanding of these topics before you start diving into code."><meta property="og:image" content="../../../../../mdn-social-share.cd6c4a5a.png"><meta property="twitter:card" content="summary_large_image"><link rel="canonical" href="Concepts.html"><style media="print">.article-actions-container,.document-toc-container,.language-menu,.main-menu-toggle,.mdn-cta-container,.on-github,.page-footer,.sidebar,.top-navigation-main,ul.prev-next{display:none!important}.main-page-content,.main-page-content pre{padding:2px}.main-page-content pre{border-left-width:2px}</style><script src="../../../../../static/js/ga.js" defer=""></script><script defer="defer" src="../../../../../static/js/main.5c9d40d0.js"></script><link href="../../../../../static/css/main.7d378400.css" rel="stylesheet"></head><body><script>document.body.addEventListener("load",(t=>{t.target.classList.contains("interactive")&&t.target.setAttribute("data-readystate","complete")}),{capture:!0});const c={light:"#ffffff",dark:"#1b1b1b"};if(window&&document.documentElement)try{const t=window.localStorage.getItem("theme");t&&(document.documentElement.className=t,document.documentElement.style.backgroundColor=c[t])}catch(t){console.warn("Unable to read theme from localStorage",t)}</script><div id="root"><ul id="nav-access" class="a11y-nav"><li><a id="skip-main" href="#content">Skip to main content</a></li><li><a id="skip-search" href="#top-nav-search-input">Skip to search</a></li><li><a id="skip-select-language" href="#languages-switcher-button">Skip to select language</a></li></ul><div class="page-wrapper  category-api document-page"><div class="main-document-header-container"><header class="main-document-header-container top-navigation 
      
      "><div class="container "><div class="top-navigation-wrap"><a href="https://developer.mozilla.org/en-US/" class="logo" aria-label="MDN homepage"><svg id="mdn-docs-logo" xmlns="http://www.w3.org/2000/svg" x="0" y="0" viewBox="0 0 694.9 104.4" style="enable-background:new 0 0 694.9 104.4" xml:space="preserve" role="img"><title>MDN Web Docs</title><style>.logo-m{fill:var(--text-link)}</style><g class="logo-m"><path d="M40.3 0 11.7 92.1H0L28.5 0h11.8zM50.7 0v92.1H40.3V0h10.4zM91 0 62.5 92.1H50.8L79.3 0H91zM101.4 0v92.1H91V0h10.4z"></path></g><path class="logo-m" d="M627.9 95.6h67v8.8h-67v-8.8z"></path><g style="fill:var(--text-primary)"><path d="M367 42h-4l-10.7 30.8h-5.5l-10.8-26h-.4l-10.5 26h-5.2L308.7 42h-3.8v-5.6H323V42h-6.5l6.8 20.4h.4l10.3-26h4.7l11.2 26h.5l5.7-20.3h-6.2v-5.6H367V42zM401.9 62c-.4 3.2-2 5.9-4.7 8.2-2.8 2.3-6.5 3.4-11.3 3.4-5.4 0-9.7-1.6-13.1-4.7-3.3-3.2-5-7.7-5-13.7 0-5.7 1.6-10.3 4.7-14s7.4-5.5 12.9-5.5c5.1 0 9.1 1.6 11.9 4.7s4.3 6.9 4.3 11.3c0 1.5-.2 3-.5 4.7h-25.6c.3 7.7 4 11.6 10.9 11.6 2.9 0 5.1-.7 6.5-2 1.5-1.4 2.5-3 3-4.9l6 .9zM394 51.3c.2-2.4-.4-4.7-1.8-6.9s-3.8-3.3-7-3.3c-3.1 0-5.3 1-6.9 3-1.5 2-2.5 4.4-2.8 7.2H394zM445 53.7c0 5-1.3 9.5-4 13.7s-6.9 6.2-12.7 6.2c-6 0-10.3-2.2-12.7-6.7-.1.4-.2 1.4-.4 2.9s-.3 2.5-.4 2.9h-7.3c.3-1.7.6-3.5.8-5.3.3-1.8.4-3.7.4-5.5V22.3h-6v-5.6H416v27c1.1-2.2 2.7-4.1 4.7-5.7 2-1.6 4.8-2.4 8.4-2.4 4.6 0 8.4 1.6 11.4 4.7 3 3.2 4.5 7.6 4.5 13.4zm-7.7.6c0-4.2-1-7.4-3-9.5-2-2.2-4.4-3.3-7.4-3.3-3.4 0-6 1.2-8 3.7-1.9 2.4-2.9 5-3 7.7V57c0 3 1 5.6 3 7.7s4.5 3.1 7.6 3.1c3.6 0 6.3-1.3 8.1-3.9 1.8-2.7 2.7-5.9 2.7-9.6zM506.5 72.8h-13.2v-7.2c-1.2 2.2-2.8 4.1-4.9 5.6-2.1 1.6-4.8 2.4-8.3 2.4-4.8 0-8.7-1.6-11.6-4.9-2.9-3.2-4.3-7.7-4.3-13.3 0-5 1.3-9.6 4-13.7 2.6-4.1 6.9-6.2 12.8-6.2 5.7 0 9.8 2.2 12.3 6.5V22.3h-8.6v-5.6h15.8v50.6h6v5.5zM493.2 56v-4.4c-.1-3-1.2-5.5-3.2-7.3s-4.4-2.8-7.2-2.8c-3.6 0-6.3 1.3-8.2 3.9-1.9 2.6-2.8 5.8-2.8 9.6 0 4.1 1 7.3 3 9.5s4.5 3.3 7.4 3.3c3.2 0 5.8-1.3 7.8-3.8 2.1-2.6 3.1-5.3 3.2-8zM546.3 54.6c0 5.6-1.8 10.2-5.3 13.7s-8.2 5.3-13.9 5.3-10.1-1.7-13.4-5.1c-3.3-3.4-5-7.9-5-13.5 0-5.3 1.6-9.9 4.7-13.7 3.2-3.8 7.9-5.7 14.2-5.7s11 1.9 14.1 5.7c3 3.7 4.6 8.1 4.6 13.3zm-7.7-.2c0-4-1-7.2-3-9.5s-4.8-3.5-8.2-3.5c-3.6 0-6.4 1.2-8.3 3.7s-2.9 5.6-2.9 9.5c0 3.7.9 6.8 2.8 9.4 1.9 2.6 4.6 3.9 8.3 3.9 3.6 0 6.4-1.3 8.4-3.8 1.9-2.6 2.9-5.8 2.9-9.7zM583.6 60.2c-.4 3.2-1.9 6.3-4.4 9.1-2.5 2.9-6.4 4.3-11.8 4.3-5.2 0-9.4-1.6-12.6-4.8-3.2-3.2-4.8-7.7-4.8-13.7 0-5.5 1.6-10.1 4.7-13.9 3.2-3.8 7.6-5.7 13.2-5.7 2.3 0 4.6.3 6.7.8 2.2.5 4.2 1.5 6.2 2.9l1.5 9.5-5.9.7-1.3-6.1c-2.1-1.2-4.5-1.8-7.2-1.8-3.5 0-6.1 1.2-7.7 3.7-1.7 2.5-2.5 5.7-2.5 9.6 0 4.1.9 7.3 2.7 9.5 1.8 2.3 4.4 3.4 7.8 3.4 5.2 0 8.2-2.9 9.2-8.8l6.2 1.3zM618.3 62.1c0 3.6-1.5 6.5-4.6 8.5s-7 3-11.7 3c-5.7 0-10.6-1.2-14.6-3.6l1.2-8.8 5.7.6-.2 4.7c1.1.5 2.3.9 3.6 1.1s2.6.3 3.9.3c2.4 0 4.5-.4 6.5-1.3 1.9-.9 2.9-2.2 2.9-4.1 0-1.8-.8-3.1-2.3-3.8s-3.5-1.3-5.8-1.7-4.6-.9-6.9-1.4c-2.3-.6-4.2-1.6-5.7-2.9-1.6-1.4-2.3-3.5-2.3-6.3 0-4.1 1.5-6.9 4.6-8.5s6.4-2.4 9.9-2.4c2.6 0 5 .3 7.2.9 2.2.6 4.3 1.4 6.1 2.4l.8 8.8-5.8.7-.8-5.7c-2.3-1-4.7-1.6-7.2-1.6-2.1 0-3.7.4-5.1 1.1-1.3.8-2 2-2 3.8 0 1.7.8 2.9 2.3 3.6 1.5.7 3.4 1.2 5.7 1.6 2.2.4 4.5.8 6.7 1.4 2.2.6 4.1 1.6 5.7 3 1.4 1.6 2.2 3.7 2.2 6.6zM197.6 73.2h-17.1v-5.5h3.8V51.9c0-3.7-.7-6.3-2.1-7.9-1.4-1.6-3.3-2.3-5.7-2.3-3.2 0-5.6 1.1-7.2 3.4s-2.4 4.6-2.5 6.9v15.6h6v5.5h-17.1v-5.5h3.8V51.9c0-3.8-.7-6.4-2.1-7.9-1.4-1.5-3.3-2.3-5.6-2.3-3.2 0-5.5 1.1-7.2 3.3-1.6 2.2-2.4 4.5-2.5 6.9v15.8h6.9v5.5h-20.2v-5.5h6V42.4h-6.1v-5.6h13.4v6.4c1.2-2.1 2.7-3.8 4.7-5.2 2-1.3 4.4-2 7.3-2s5.3.7 7.5 2.1c2.2 1.4 3.7 3.5 4.5 6.4 1.1-2.5 2.7-4.5 4.9-6.1s4.8-2.4 7.9-2.4c3.5 0 6.5 1.1 8.9 3.3s3.7 5.6 3.7 10.2v18.2h6.1v5.5zm42.5 0h-13.2V66c-1.2 2.2-2.8 4.1-4.9 5.6-2.1 1.6-4.8 2.4-8.3 2.4-4.8 0-8.7-1.6-11.6-4.9-2.9-3.2-4.3-7.7-4.3-13.3 0-5 1.3-9.6 4-13.7 2.6-4.1 6.9-6.2 12.8-6.2s9.8 2.2 12.3 6.5V22.7h-8.6v-5.6h15.8v50.6h6v5.5zm-13.3-16.8V52c-.1-3-1.2-5.5-3.2-7.3s-4.4-2.8-7.2-2.8c-3.6 0-6.3 1.3-8.2 3.9-1.9 2.6-2.8 5.8-2.8 9.6 0 4.1 1 7.3 3 9.5s4.5 3.3 7.4 3.3c3.2 0 5.8-1.3 7.8-3.8 2.1-2.6 3.1-5.3 3.2-8zm61.5 16.8H269v-5.5h6V51.9c0-3.7-.7-6.3-2.2-7.9-1.4-1.6-3.4-2.3-5.7-2.3-3.1 0-5.6 1-7.4 3s-2.8 4.4-2.9 7v15.9h6v5.5h-19.3v-5.5h6V42.4h-6.2v-5.6h13.6V43c2.6-4.6 6.8-6.9 12.7-6.9 3.6 0 6.7 1.1 9.2 3.3s3.7 5.6 3.7 10.2v18.2h6v5.4h-.2z"></path></g></svg></a><button title="Open main menu" type="button" class="button action has-icon main-menu-toggle" aria-haspopup="menu" aria-label="Open main menu" aria-expanded="false"><span class="button-wrap"><span class="icon icon-menu "></span><span class="visually-hidden">Open main menu</span></span></button></div><div class="top-navigation-main"><nav class="main-nav" aria-label="Main menu"><ul class="main-menu nojs"><li class="top-level-entry-container"><button type="button" id="references-button" class="top-level-entry menu-toggle" aria-controls="references-menu" aria-expanded="false">References</button><a href="https://developer.mozilla.org/en-US/docs/Web" class="top-level-entry">References</a><ul id="references-menu" class="submenu references hidden inline-submenu-lg" aria-labelledby="references-button"><li class="apis-link-container mobile-only "><a href="https://developer.mozilla.org/en-US/docs/Web" class="submenu-item "><div class="submenu-icon"></div><div class="submenu-content-container"><div class="submenu-item-heading">Overview / Web Technology</div><p class="submenu-item-description">Web technology reference for developers</p></div></a></li><li class="html-link-container "><a href="https://developer.mozilla.org/en-US/docs/Web/HTML" class="submenu-item "><div class="submenu-icon html"></div><div class="submenu-content-container"><div class="submenu-item-heading">HTML</div><p class="submenu-item-description">Structure of content on the web</p></div></a></li><li class="css-link-container "><a href="https://developer.mozilla.org/en-US/docs/Web/CSS" class="submenu-item "><div class="submenu-icon css"></div><div class="submenu-content-container"><div class="submenu-item-heading">CSS</div><p class="submenu-item-description">Code used to describe document style</p></div></a></li><li class="javascript-link-container "><a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript" class="submenu-item "><div class="submenu-icon javascript"></div><div class="submenu-content-container"><div class="submenu-item-heading">JavaScript</div><p class="submenu-item-description">General-purpose scripting language</p></div></a></li><li class="http-link-container "><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP" class="submenu-item "><div class="submenu-icon http"></div><div class="submenu-content-container"><div class="submenu-item-heading">HTTP</div><p class="submenu-item-description">Protocol for transmitting web resources</p></div></a></li><li class="apis-link-container "><a href="../../API.html" class="submenu-item "><div class="submenu-icon apis"></div><div class="submenu-content-container"><div class="submenu-item-heading">Web APIs</div><p class="submenu-item-description">Interfaces for building web applications</p></div></a></li><li class="apis-link-container "><a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions" class="submenu-item "><div class="submenu-icon"></div><div class="submenu-content-container"><div class="submenu-item-heading">Web Extensions</div><p class="submenu-item-description">Developing extensions for web browsers</p></div></a></li><li class="apis-link-container desktop-only "><a href="https://developer.mozilla.org/en-US/docs/Web" class="submenu-item "><div class="submenu-icon"></div><div class="submenu-content-container"><div class="submenu-item-heading">Web Technology</div><p class="submenu-item-description">Web technology reference for developers</p></div></a></li></ul></li><li class="top-level-entry-container"><button type="button" id="guides-button" class="top-level-entry menu-toggle" aria-controls="guides-menu" aria-expanded="false">Guides</button><a href="https://developer.mozilla.org/en-US/docs/Learn" class="top-level-entry">Guides</a><ul id="guides-menu" class="submenu guides hidden inline-submenu-lg" aria-labelledby="guides-button"><li class="apis-link-container mobile-only "><a href="https://developer.mozilla.org/en-US/docs/Learn" class="submenu-item "><div class="submenu-icon learn"></div><div class="submenu-content-container"><div class="submenu-item-heading">Overview / MDN Learning Area</div><p class="submenu-item-description">Learn web development</p></div></a></li><li class="apis-link-container desktop-only "><a href="https://developer.mozilla.org/en-US/docs/Learn" class="submenu-item "><div class="submenu-icon learn"></div><div class="submenu-content-container"><div class="submenu-item-heading">MDN Learning Area</div><p class="submenu-item-description">Learn web development</p></div></a></li><li class="html-link-container "><a href="https://developer.mozilla.org/en-US/docs/Learn/HTML" class="submenu-item "><div class="submenu-icon html"></div><div class="submenu-content-container"><div class="submenu-item-heading">HTML</div><p class="submenu-item-description">Learn to structure web content with HTML</p></div></a></li><li class="css-link-container "><a href="https://developer.mozilla.org/en-US/docs/Learn/CSS" class="submenu-item "><div class="submenu-icon css"></div><div class="submenu-content-container"><div class="submenu-item-heading">CSS</div><p class="submenu-item-description">Learn to style content using CSS</p></div></a></li><li class="javascript-link-container "><a href="https://developer.mozilla.org/en-US/docs/Learn/JavaScript" class="submenu-item "><div class="submenu-icon javascript"></div><div class="submenu-content-container"><div class="submenu-item-heading">JavaScript</div><p class="submenu-item-description">Learn to run scripts in the browser</p></div></a></li><li class=" "><a href="https://developer.mozilla.org/en-US/docs/Web/Accessibility" class="submenu-item "><div class="submenu-icon"></div><div class="submenu-content-container"><div class="submenu-item-heading">Accessibility</div><p class="submenu-item-description">Learn to make the web accessible to all</p></div></a></li></ul></li><li class="top-level-entry-container"><button type="button" id="mdn-plus-button" class="top-level-entry menu-toggle" aria-controls="mdn-plus-menu" aria-expanded="false">MDN Plus</button><a href="https://developer.mozilla.org/en-US/plus" class="top-level-entry">MDN Plus</a><ul id="mdn-plus-menu" class="submenu mdn-plus hidden inline-submenu-lg" aria-labelledby="mdn-plus-button"><li class=" "><a href="https://developer.mozilla.org/en-US/plus" class="submenu-item "><div class="submenu-icon"></div><div class="submenu-content-container"><div class="submenu-item-heading">Overview</div><p class="submenu-item-description">A customized MDN experience</p></div></a></li><li class=" "><a href="https://developer.mozilla.org/en-US/plus/updates" class="submenu-item "><div class="submenu-icon"></div><div class="submenu-content-container"><div class="submenu-item-heading">Updates</div><p class="submenu-item-description">All browser compatibility updates at a glance</p></div></a></li><li class=" "><a href="https://developer.mozilla.org/en-US/plus/docs/features/overview" class="submenu-item "><div class="submenu-icon"></div><div class="submenu-content-container"><div class="submenu-item-heading">Documentation</div><p class="submenu-item-description">Learn how to use MDN Plus</p></div></a></li><li class=" "><a href="https://developer.mozilla.org/en-US/plus/docs/faq" class="submenu-item "><div class="submenu-icon"></div><div class="submenu-content-container"><div class="submenu-item-heading">FAQ</div><p class="submenu-item-description">Frequently asked questions about MDN Plus</p></div></a></li></ul></li></ul></nav><div class="header-search"><form action="https://developer.mozilla.org/en-US/search" role="search" aria-haspopup="listbox" aria-owns="top-nav-search-menu" aria-expanded="false" class="search-form search-widget" id="top-nav-search-form"><label id="top-nav-search-label" for="top-nav-search-input" class="visually-hidden">Search MDN</label><input id="top-nav-search-input" aria-autocomplete="list" aria-controls="top-nav-search-menu" aria-labelledby="top-nav-search-label" autocomplete="off" type="search" class="search-input-field" name="q" placeholder="   " required="" value=""><button type="button" class="button action has-icon clear-search-button"><span class="button-wrap"><span class="icon icon-cancel "></span><span class="visually-hidden">Clear search input</span></span></button><button type="submit" class="button action has-icon search-button"><span class="button-wrap"><span class="icon icon-search "></span><span class="visually-hidden">Search</span></span></button><div id="top-nav-search-menu" role="listbox" aria-labelledby="top-nav-search-label"></div></form></div><div class="theme-switcher-menu"><button type="button" class="button action has-icon theme-switcher-menu small" aria-haspopup="menu"><span class="button-wrap"><span class="icon icon-theme-os-default "></span>Theme</span></button></div><ul class="auth-container"><li><a href="https://developer.mozilla.org/users/fxa/login/authenticate/?next=%2Fen-US%2Fdocs%2FWeb%2FAPI%2FWebVR_API%2FConcepts" class="signin-link" rel="nofollow">Already a subscriber?</a></li><li><a class="button primary mdn-plus-subscribe-link" href="https://developer.mozilla.org/en-US/plus"><span class="button-wrap">Get MDN Plus</span></a></li></ul></div></div></header><div class="article-actions-container"><div class="container"><button type="button" class="button action has-icon sidebar-button" aria-label="Expand sidebar" aria-expanded="false" aria-controls="sidebar-quicklinks"><span class="button-wrap"><span class="icon icon-sidebar "></span></span></button><nav class="breadcrumbs-container" aria-label="Breadcrumb"><ol typeof="BreadcrumbList" vocab="https://schema.org/" aria-label="breadcrumbs"><li property="itemListElement" typeof="ListItem"><a class="breadcrumb" property="item" typeof="WebPage" href="https://developer.mozilla.org/en-US/docs/Web"><span property="name">References</span></a><meta property="position" content="1"></li><li property="itemListElement" typeof="ListItem"><a class="breadcrumb" property="item" typeof="WebPage" href="../../API.html"><span property="name">Web APIs</span></a><meta property="position" content="2"></li><li property="itemListElement" typeof="ListItem"><a class="breadcrumb" property="item" typeof="WebPage" href="../WebVR_API.html"><span property="name">WebVR API</span></a><meta property="position" content="3"></li><li property="itemListElement" typeof="ListItem"><a class="breadcrumb-current-page" property="item" typeof="WebPage" href="Concepts.html"><span property="name">WebVR concepts</span></a><meta property="position" content="4"></li></ol></nav><div class="article-actions"><button type="button" class="button action has-icon article-actions-toggle" aria-label="Article actions"><span class="button-wrap"><span class="icon icon-ellipses "></span><span class="article-actions-dialog-heading">Article Actions</span></span></button><ul class="article-actions-entries"><li class="article-actions-entry"><div class="languages-switcher-menu open-on-focus-within"><button id="languages-switcher-button" type="button" class="button action small has-icon languages-switcher-menu" aria-haspopup="menu"><span class="button-wrap"><span class="icon icon-language "></span>English (US)</span></button></div></li></ul></div></div></div></div><div class="main-wrapper"><aside id="sidebar-quicklinks" class="sidebar"><button type="button" class="button action backdrop" aria-label="Collapse sidebar"><span class="button-wrap"></span></button><nav aria-label="Related Topics" class="sidebar-inner"><div class="in-nav-toc"><div class="document-toc-container"><section class="document-toc"><header><h2 class="document-toc-heading">In this article</h2></header><ul class="document-toc-list"><li class="document-toc-item "><a class="document-toc-link" href="#the_history_of_vr">The history of VR</a></li><li class="document-toc-item "><a class="document-toc-link" href="#vr_hardware_setup">VR Hardware setup</a></li><li class="document-toc-item "><a class="document-toc-link" href="#position_and_orientation_velocity_and_acceleration">Position and orientation, velocity and acceleration</a></li><li class="document-toc-item "><a class="document-toc-link" href="#field_of_view">Field of view</a></li><li class="document-toc-item "><a class="document-toc-link" href="#concepts_for_vr_apps">Concepts for VR apps</a></li></ul></section></div></div><div><ol><li><strong><a href="../WebVR_API.html">WebVR API</a></strong></li><li><strong><a href="../WebVR_API.html"><code>WebVR_API</code></a></strong></li><li class="toggle"><details open=""><summary>Related pages for WebVR API</summary><ol><li><a href="../Gamepad/displayId.html"><code>Gamepad.displayId</code></a></li><li><a href="../Navigator/activeVRDisplays.html"><code>Navigator.activeVRDisplays</code></a></li><li><a href="../Navigator/getVRDisplays.html"><code>Navigator.getVRDisplays()</code></a></li><li><a href="../VRDisplay.html"><code>VRDisplay</code></a></li><li><a href="../VRDisplayCapabilities.html"><code>VRDisplayCapabilities</code></a></li><li><a href="../VRDisplayEvent.html"><code>VRDisplayEvent</code></a></li><li><a href="../VREyeParameters.html"><code>VREyeParameters</code></a></li><li><a href="../VRFieldOfView.html"><code>VRFieldOfView</code></a></li><li><a href="../VRFrameData.html"><code>VRFrameData</code></a></li><li><a href="../VRLayerInit.html"><code>VRLayerInit</code></a></li><li><a href="../VRPose.html"><code>VRPose</code></a></li><li><a href="../VRStageParameters.html"><code>VRStageParameters</code></a></li></ol></details></li></ol></div></nav></aside><aside class="toc"><nav><div class="document-toc-container"><section class="document-toc"><header><h2 class="document-toc-heading">In this article</h2></header><ul class="document-toc-list"><li class="document-toc-item "><a class="document-toc-link" href="#the_history_of_vr">The history of VR</a></li><li class="document-toc-item "><a class="document-toc-link" href="#vr_hardware_setup">VR Hardware setup</a></li><li class="document-toc-item "><a class="document-toc-link" href="#position_and_orientation_velocity_and_acceleration">Position and orientation, velocity and acceleration</a></li><li class="document-toc-item "><a class="document-toc-link" href="#field_of_view">Field of view</a></li><li class="document-toc-item "><a class="document-toc-link" href="#concepts_for_vr_apps">Concepts for VR apps</a></li></ul></section></div></nav></aside><main id="content" class="main-content  "><article class="main-page-content" lang="en-US"><h1>WebVR concepts</h1><div class="section-content"><div class="notecard deprecated" id="sect1"><p><strong>Deprecated:</strong> This feature is no longer recommended. Though some browsers might still support it, it may have already been removed from the relevant web standards, may be in the process of being dropped, or may only be kept for compatibility purposes. Avoid using it, and update existing code if possible; see the <a href="#browser_compatibility">compatibility table</a> at the bottom of this page to guide your decision. Be aware that this feature may cease to work at any time.</p></div>
<div class="notecard note" id="sect2">
  <p><strong>Note:</strong> WebVR API is replaced by <a href="../WebXR_Device_API.html">WebXR API</a>. WebVR was never ratified as a standard, was implemented and enabled by default in very few browsers and supported a small number of devices.</p>
</div>
<p>This article discusses some of the concepts and theory behind virtual reality (VR). If you are a newcomer to the area, it is worthwhile getting an understanding of these topics before you start diving into code.</p></div><section aria-labelledby="the_history_of_vr"><a class="dashAnchor" name="//apple_ref/Section/The%20history%20of%20VR"></a><h2 id="the_history_of_vr"><a href="#the_history_of_vr">The history of VR</a></h2><div class="section-content"><p>Virtual reality is nothing new — the concept goes way further back than the Oculus Rift Kickstarter campaign of 2012. People have been experimenting with it for decades.</p>
<p>In 1939 the <a href="https://en.wikipedia.org/wiki/View-Master" class="external" target="_blank">View-Master device</a> was created, allowing people to see 3D pictures. The device displayed images stored on cardboard disks containing stereoscopic 3D pairs of small color photographs. After years of development the military got interested in using such technology, and Project Headsight was born in 1961 — this involved a helmet incorporating a video screen with a head-tracking system.</p>
<p>There were various experiments conducted over the next few decades, but it wasn't restricted to science labs and battlefields anymore. Eventually pop culture took over with movie directors showing their visions of virtual reality. Movies like Tron (1982) and The Matrix (1999) were created, where people could transfer themselves into a whole new cyber world or were trapped in one without even knowing, accepting it as the real world.</p>
<p>The first VR gaming attempts were big and expensive — in 1991 Virtuality Group created a VR-ready arcade machine with goggles and ported popular titles like Pac-Man to virtual reality. Sega introduced their VR glasses at the Consumer Electronics Show in 1993. Companies were experimenting, but the market and consumers weren't convinced — we had to wait until 2012 to see a real example of a successful VR project.</p></div></section><section aria-labelledby="vr_in_recent_times"><h3 id="vr_in_recent_times"><a href="#vr_in_recent_times">VR in recent times</a></h3><div class="section-content"><p>So what's new? Virtual Reality hardware needs to deliver high-precision, low-latency data to deliver an acceptable user experience; computers running VR applications need to be powerful enough to handle all this information. It has not been until recently that such accuracy and power has been available at an affordable cost, if at all. Early VR prototypes cost tens of thousands of dollars, whereas more recent headsets such as the <a href="https://www.vive.com/uk/" class="external" target="_blank">HTC VIVE</a> and <a href="https://www.oculus.com/rift/" class="external" target="_blank">Oculus Rift</a> are available for hundreds of dollars, and cheaper solutions are available — mobile device-based solutions like <a href="https://www.samsung.com/global/galaxy/what-is/gear-vr/" class="external" target="_blank">Gear VR</a> and <a href="https://arvr.google.com/cardboard/" class="external" target="_blank">Google Cardboard</a>.</p>
<p>On the software side, Valve has created <a href="https://store.steampowered.com/search/?category1=993" class="external" target="_blank">SteamVR</a> software, which is compatible with the VIVE and other solutions, and serves to provide access to software, such as a usable VR UI.</p>
<p>The technology itself is here, and the more expensive headsets will only get cheaper over time so more people can experience virtual reality on their own in the future.</p></div></section><section aria-labelledby="input_devices"><h3 id="input_devices"><a href="#input_devices">Input devices</a></h3><div class="section-content"><p>Handling input for virtual reality applications is an interesting topic — it's a totally new experience for which dedicated user interfaces have to be designed. There are various approaches right now from classic keyboard and mouse, to new ones like Leap Motion and the VIVE controllers. It's a matter of trial and error to see what works in given situations and what inputs fit best for your type of game.</p></div></section><section aria-labelledby="vr_hardware_setup"><a class="dashAnchor" name="//apple_ref/Section/VR%20Hardware%20setup"></a><h2 id="vr_hardware_setup"><a href="#vr_hardware_setup">VR Hardware setup</a></h2><div class="section-content"><p>There are two main types of setup, mobile or computer-connected. Their minimum hardware set ups are as follows:</p>
<ul>
  <li>Mobile: A Head-mounted display (HMD) is created using a smartphone — which acts as the VR display — mounted in a VR mount such as Google Cardboard, which contains the required lenses to provide stereoscopic vision of what is projected on the mobile screen.
    <img src="Concepts/mobilebasedvrsetup.png" alt="Mobile based VR setup" width="1280" height="400" loading="lazy">
  </li>
  <li>Computer-connected: A VR setup is connected to your computer — this consists of a Head Mounted Display (HMD) containing a high resolution landscape-oriented screen onto which the visuals for both the left and right eye are displayed, which also includes a lens for each eye to promote separation of the left and right eye scene (stereoscopic vision.) The setup also includes a separate position sensor that works out the position/orientation/velocity/acceleration of your head and constantly passes that information the computer. 
    <img src="Concepts/computerbasedvrsetup.png" alt="Computer based VR Setup" width="1280" height="500" loading="lazy">
  </li>
</ul>
<div class="notecard note" id="sect3">
  <p><strong>Note:</strong> Computer-connected systems sometimes don't include a position sensor, but they usually do.</p>
</div>
<p>Other hardware that complements the VR experience includes:</p>
<ul>
  <li><strong>A hand recognition sensor</strong>: A sensor that tracks the position and movement of your hand, allowing it to become an interesting controller, and an object in VR gameworlds. The most advanced to date is the <a href="https://www.ultraleap.com/" class="external" target="_blank">Leap Motion</a>, which works with the computer (connected to the Oculus Rift) and can also work connected to a mobile device (the latter is in an experimental phase.)</li>
  <li><strong>A gamepad</strong>: We can configure an XBox controller or similar to work as a keyboard in the browser — this offers further possibilities of interaction with a VR webpage. There are some gamepads that work with a mobile setup but these are connected via Bluetooth so don't work with WebVR.</li>
  <li><strong>An eye tracking sensor (experimental)</strong>: The FOVE project is the first headset that reads subtle eye movements.</li>
  <li><strong>A facial expression tracker (experimental)</strong>: Researchers at the University of Southern California and Facebook's Oculus division have been testing new ways of tracking facial expressions and transferring them to a virtual character.</li>
  <li><strong>A more complex positional sensor system</strong>: As an example, the HTC VIVE features two position sensors that sit in opposite corners of a space, mapping it all out and allowing VR experiences to be enjoyed in spaces of up to 5m x 5m.</li>
</ul></div></section><section aria-labelledby="position_and_orientation_velocity_and_acceleration"><a class="dashAnchor" name="//apple_ref/Section/Position%20and%20orientation%2C%20velocity%20and%20acceleration"></a><h2 id="position_and_orientation_velocity_and_acceleration"><a href="#position_and_orientation_velocity_and_acceleration">Position and orientation, velocity and acceleration</a></h2><div class="section-content"><p>As mentioned above, the position sensor detects information concerning the HMD and constantly outputs it, allowing you to continually update a scene according to head movement, rotation, etc. But what exactly is the information?</p>
<p>
  <img src="Concepts/positionorientationvr.png" alt="Position and Orientation VR setup" width="1280" height="500" loading="lazy">
</p>
<p>The output information falls into four categories:</p>
<ol>
  <li>Position — The position of the HMD along three axes in a 3D coordinate space. x is to the left and right, y is up and down, and z is towards and away from the position sensor. In WebVR, the x, y, and z coordinates are represented by the array contained in <a href="../VRPose/position.html"><code>VRPose.position</code></a>.</li>
  <li>Orientation — The rotation of the HMD around three axes in a 3D coordinate space. Pitch is rotation around the x axis, yaw is rotation around the y axis, and roll is rotation around the z axis. In WebVR, the pitch, yaw, and roll are represented by the first three elements of the array contained in <a href="../VRPose/orientation.html"><code>VRPose.orientation</code></a>.</li>
  <li>Velocity — There are two types of velocity to consider in VR:
    <ul>
      <li>Linear — The speed along any one of the axes that the HMD is traveling. This information can be accessed using <a href="../VRPose/linearVelocity.html"><code>VRPose.linearVelocity</code></a>.</li>
      <li>Angular — The speed at which the HMD is rotating around any one of the axes. This information can be accessed using <a href="../VRPose/angularVelocity.html"><code>VRPose.angularVelocity</code></a>.</li>
    </ul>
  </li>
  <li>Acceleration — There are two types of acceleration to consider in VR:
    <ul>
      <li>Linear — The acceleration of travel along any one of the axes that the HMD is traveling. This information can be accessed using <a href="../VRPose/linearAcceleration.html"><code>VRPose.linearAcceleration</code></a>.</li>
      <li>Angular — The acceleration of rotation of the HMD around any one of the axes. This information can be accessed using <a href="../VRPose/angularAcceleration.html"><code>VRPose.angularAcceleration</code></a>.</li>
    </ul>
  </li>
</ol></div></section><section aria-labelledby="field_of_view"><a class="dashAnchor" name="//apple_ref/Section/Field%20of%20view"></a><h2 id="field_of_view"><a href="#field_of_view">Field of view</a></h2><div class="section-content"><p>The field of view (FOV) is the area that each of the user's eyes can reasonably be expected to see. It roughly takes the form of a pyramid shape, laid down on one side, with the apex inside the user's head, and the rest of the pyramid emanating from the user's eye. Each eye has its own FOV, one slightly overlapping the other.</p>
<p>
  <img src="Concepts/fovrelatedproperties.png" alt="FOV related properties" width="1280" height="500" loading="lazy">
</p>
<p>The FOV is defined by the following values:</p>
<ul>
  <li><a href="../VRFieldOfView/upDegrees.html"><code>VRFieldOfView.upDegrees</code></a>: The number of degrees upwards that the field of view extends in.</li>
  <li><a href="../VRFieldOfView/rightDegrees.html"><code>VRFieldOfView.rightDegrees</code></a>: The number of degrees to the right that the field of view extends in.</li>
  <li><a href="../VRFieldOfView/downDegrees.html"><code>VRFieldOfView.downDegrees</code></a>: The number of degrees downwards that the field of view extends in.</li>
  <li><a href="../VRFieldOfView/leftDegrees.html"><code>VRFieldOfView.leftDegrees</code></a>: The number of degrees to the left that the field of view extends in.</li>
  <li>zNear, defined by <a href="../VRDisplay/depthNear.html"><code>VRDisplay.depthNear</code></a>: The distance from the middle of the user's head to the start of the visible FOV.</li>
  <li>zFar, defined by <a href="../VRDisplay/depthFar.html"><code>VRDisplay.depthFar</code></a>: The distance from the middle of the user's head to the end of the visible FOV.</li>
</ul>
<p>The default values for these properties will differ slightly by VR hardware, although they tend to be around 53° up and down, and 47° left and right, with zNear and zFar coming in at around 0.1m and 10000m respectively.</p>
<div class="notecard note" id="sect4">
  <p><strong>Note:</strong> The user can potentially see all the way around them, which is a brand new concept for apps and games. Try to give people a reason to look around and see what's behind them — make them reach out and find things that are not visible at the very beginning. Describe what's behind their backs.</p>
</div></div></section><section aria-labelledby="concepts_for_vr_apps"><a class="dashAnchor" name="//apple_ref/Section/Concepts%20for%20VR%20apps"></a><h2 id="concepts_for_vr_apps"><a href="#concepts_for_vr_apps">Concepts for VR apps</a></h2><div class="section-content"><p>This section discusses concepts to be aware of when developing VR apps that you've probably not had to consider before when developing regular apps for mobile or desktop.</p></div></section><section aria-labelledby="stereoscopic_vision"><h3 id="stereoscopic_vision"><a href="#stereoscopic_vision">Stereoscopic vision</a></h3><div class="section-content"><p>Stereoscopic vision is the normal vision humans and (most) animals have — the perception of two slightly differing images (one from each eye) as a single image. This results in depth perception, helping us to see the world in glorious 3D. To recreate this in VR apps, you need to render two very slightly different views side by side, which will be taken in by the left and right eyes when the user is using the HMD.</p>
<p>
  <img src="Concepts/createstereoscopicimages.png" alt="How to create stereoscopic 3D images" width="1280" height="500" loading="lazy">
</p></div></section><section aria-labelledby="head_tracking"><h3 id="head_tracking"><a href="#head_tracking">Head tracking</a></h3><div class="section-content"><p>
  The primary technology used to make you feel present in a 360º scene, thanks to the gyroscope, accelerometer, and magnetometer (compass) included in the HMD.
  It has primary relevance because it makes our eyes believe we are in front of a spherical screen, giving users realistic immersion inside the app canvas.
</p></div></section><section aria-labelledby="eye_strain"><h3 id="eye_strain"><a href="#eye_strain">Eye strain</a></h3><div class="section-content"><p>A term commonly used in VR because it is a major handicap of using an HMD — we are constantly fooling the eye with what we are showing in the app canvas, and this leads to the eyes doing a lot more work than they normally would, so using VR apps for any extended period of time can lead to eye strain.</p>
<p>To minimize this unwanted effect, we need to:</p>
<ul>
  <li>Avoid focusing on different depths (e.g. avoid using a lot of particles with different depths.)</li>
  <li>Avoid eye convergence (e.g. if you have an object that comes towards the camera your eyes will follow and converge on it.)</li>
  <li>Use darker backgrounds with more subdued colors where possible; a bright screen will make the eyes more tired.</li>
  <li>Avoid rapid brightness changes.</li>
  <li>Avoid presenting the user with large amounts of text to read. You should also be careful with the distance between the eyes/camera and the text to read. 0.5m is uncomfortable, whereas at more than 2m the stereo effect starts to break down, so somewhere in between is advisable.</li>
  <li>Be careful with the distance between objects and the camera in general. Oculus recommends 0.75m as a minimum distance of focus.</li>
  <li>Use a pointer if the user needs to interact with an object in the scene — this will help them point to it correctly with less effort.</li>
</ul>
<p>In general, the path of least visual effort will give the user a less tiring experience.</p></div></section><section aria-labelledby="motion_sickness"><h3 id="motion_sickness"><a href="#motion_sickness">Motion sickness</a></h3><div class="section-content"><p>If developers do not take utmost care, VR apps can actually cause their users to feel sick. This effect is produced when the stimuli their eyes are receiving is not what the body expects to receive.</p>
<p>To avoid bringing on motion sickness in our users (or at least minimize the effects), we need to:</p>
<ul>
  <li>Always maintain head tracking (this is the most important of all, especially if it occurs in middle of the experience.)</li>
  <li>Use constant velocity; avoid acceleration or deceleration camera movements (use linear acceleration, and avoid easing if you can.)</li>
  <li>Keep the frame rate up (less than 30fps is uncomfortable.)</li>
  <li>Avoid sharp and/or unexpected camera rotations.</li>
  <li>Add fixed points of reference for fixed objects (otherwise the user will believe they are on the move.)</li>
  <li>Do not use Depth of Field or Motion Blur post processing because you do not know where the eyes will focus.</li>
  <li>Avoid brightness changes (use low frequency textures or fog effects to create smooth lighting transitions).</li>
</ul>
<p>Overall your eyes should not send signals to the brain that cause reflex actions in other parts of the body.</p></div></section><section aria-labelledby="latency"><h3 id="latency"><a href="#latency">Latency</a></h3><div class="section-content"><p>Latency is the time between the physical head movement and the visual display reaching the user's eyes from the screen of an HMD being updated. This is one of the most critical factors in providing a realistic experience. Humans can detect very small delays — we need to keep the latency below 20 milliseconds if they are to be imperceptible (for example a 60Hz monitor has a 16 ms response.)</p>
<p>The Oculus Rift headset has a latency of 20 ms or less, but with mobile device-based setups it will depend heavily on the smartphone CPU power and other capabilities.</p></div></section><section aria-labelledby="frame_rate_frames_per_second_fps"><h3 id="frame_rate_frames_per_second_fps"><a href="#frame_rate_frames_per_second_fps">Frame rate (Frames per second / FPS)</a></h3><div class="section-content"><p>Based on the Wikipedia definition, frame rate is the frequency at which an imaging device produces unique consecutive images, called frames. A rate of 60fps is an acceptable rate for a smooth user experience, but depending on the performance of the machine the app is running on, or the complexity of the content you want to show, it can drastically lower. Less than 30fps is generally considered jittery, and annoying to the user.</p>
<p>One of the most difficult tasks is to maintain a constant and high frame rate value, so we must optimize our code to make it as efficient as possible. It is preferable to have a decent frame rate that doesn't constantly or suddenly change; for this you need to as few necessary objects moving into the scene as possible and (in the case of WebGL) try to reduce draw calls.</p></div></section><section aria-labelledby="interpupillary_distance_ipd"><h3 id="interpupillary_distance_ipd"><a href="#interpupillary_distance_ipd">Interpupillary distance (IPD)</a></h3><div class="section-content"><p>Based on the Wikipedia definition, IPD is the distance between the centers of the pupils of the two eyes. IPD is critical for the design of binocular viewing systems, where both eye pupils need to be positioned within the exit pupils of the viewing system.</p>
<p>Interpupillary distance (IPD) can be calculated using <a href="../VREyeParameters/offset.html"><code>VREyeParameters.offset</code></a> in WebVR, which is equal to half the IPD.</p>
<p>This value is returned by the HMD and its value may be around 60 to 70 mm; in the case of some HMDs like Oculus Rift's, you can set your own IPD. Normally we don't change this value but you can play with it to change the scale of the entire scene. For example, if your IPD is set to 6000 mm, the user would view the scene like a giant looking at a Lilliputian world.</p></div></section><section aria-labelledby="degrees_of_freedom_dof"><h3 id="degrees_of_freedom_dof"><a href="#degrees_of_freedom_dof">Degrees of Freedom (DoF)</a></h3><div class="section-content"><p>DoF refers to the movement of a rigid body inside space. There is no uniformity in creating acronyms for this term — we can find references to 3DoF in the context of sensors that detect only rotational head tracking, and 6DoF when an input allows us to control position and orientation simultaneously. We even sometimes find 9DoF references when the hardware contains three sensors like gyroscope, accelerometer and magnetometer, but the results of the 3 x 3DoF values will actually return a 6 degrees of freedom tracking.</p>
<p>DoF is directly related to the tracking of the user's head movement.</p></div></section><section aria-labelledby="cone_of_focus"><h3 id="cone_of_focus"><a href="#cone_of_focus">Cone of focus</a></h3><div class="section-content"><p>Although our field of view is much larger (approximately 180º), we need to be aware that only in a small portion of that field can you perceive symbols (the center 60º) or read text (the center 10º). If you do not have an eye tracking sensor we assume that the center of the screen is where the user is focusing their eyes.</p>
<p>This limitation is important to consider when deciding where to place visuals on the app canvas — too far toward the edge of the cone of focus can lead to eye strain much more quickly. There is a very interesting post about this (amongst other things) at <a href="https://mixedreality.mozilla.org/%3E" class="external" target="_blank">Mozilla's Mixed Reality site</a> — in particular, read <a href="https://blog.mozvr.com/quick-vr-prototypes/" class="external" target="_blank">Quick VR Mockups with Illustrator</a>.</p></div></section><section aria-labelledby="3d_positional_audio"><h3 id="3d_positional_audio"><a href="#3d_positional_audio">3D Positional Audio</a></h3><div class="section-content"><p>3D positional audio refers to a group of effects that manipulate audio to simulate how it would sound in a three dimensional space.</p>
<p>This directly related to the <a href="../Web_Audio_API.html">Web Audio API</a>, which allows us to place sounds on objects we have in the canvas or launch audio depending on the part of the scene the user is traveling towards or looking at.</p></div></section><aside class="metadata"><div class="metadata-content-container"><div id="on-github" class="on-github"><h3>Found a content problem with this page?</h3><ul><li>Edit the page <a href="https://github.com/mdn/content/edit/main/files/en-us/web/api/webvr_api/concepts/index.md" title="This will take you to GitHub, where you'll need to sign in first." target="_blank" rel="noopener noreferrer">on GitHub</a>.</li><li>Report the <a href="https://github.com/mdn/content/issues/new?template=page-report.yml&amp;mdn-url=https%3A%2F%2Fdeveloper.mozilla.org%2Fen-US%2Fdocs%2FWeb%2FAPI%2FWebVR_API%2FConcepts&amp;metadata=%3C%21--+Do+not+make+changes+below+this+line+--%3E%0A%3Cdetails%3E%0A%3Csummary%3EPage+report+details%3C%2Fsummary%3E%0A%0A*+Folder%3A+%60en-us%2Fweb%2Fapi%2Fwebvr_api%2Fconcepts%60%0A*+MDN+URL%3A+https%3A%2F%2Fdeveloper.mozilla.org%2Fen-US%2Fdocs%2FWeb%2FAPI%2FWebVR_API%2FConcepts%0A*+GitHub+URL%3A+https%3A%2F%2Fgithub.com%2Fmdn%2Fcontent%2Fblob%2Fmain%2Ffiles%2Fen-us%2Fweb%2Fapi%2Fwebvr_api%2Fconcepts%2Findex.md%0A*+Last+commit%3A+https%3A%2F%2Fgithub.com%2Fmdn%2Fcontent%2Fcommit%2F13dc8d707abd26319eba06d9c48630eb25e9adb9%0A*+Document+last+modified%3A+2023-01-09T02%3A31%3A42.000Z%0A%0A%3C%2Fdetails%3E" title="This will take you to GitHub to file a new issue." target="_blank" rel="noopener noreferrer">content issue</a>.</li><li>View the source <a href="https://github.com/mdn/content/blob/main/files/en-us/web/api/webvr_api/concepts/index.md?plain=1" title="Folder: en-us/web/api/webvr_api/concepts (Opens in a new tab)" target="_blank" rel="noopener noreferrer">on GitHub</a>.</li></ul>Want to get more involved? Learn<!-- --> <a href="https://github.com/mdn/content/blob/main/CONTRIBUTING.md" title="This will take you to our contribution guidelines on GitHub." target="_blank" rel="noopener noreferrer">how to contribute</a>.</div><p class="last-modified-date">This page was last modified on<!-- --> <time datetime="2023-01-09T02:31:42.000Z">Jan 9, 2023</time> by<!-- --> <a href="Concepts/contributors.txt">MDN contributors</a>.</p></div></aside></article></main></div><footer id="nav-footer" class="page-footer"><div><a href="http://developer.mozilla.org/en-US/docs/Web/API/WebVR_API/Concepts">WebVR concepts</a> by <a href="http://developer.mozilla.org/en-US/docs/Web/API/WebVR_API/Concepts$history">Mozilla Contributors</a> is licensed under <a href="http://creativecommons.org/licenses/by-sa/2.5/">CC-BY-SA 2.5</a>.</div></footer></div></div><script type="application/json" id="hydration">{"doc":{"isMarkdown":true,"isTranslated":false,"isActive":true,"flaws":{},"title":"WebVR concepts","mdn_url":"/en-US/docs/Web/API/WebVR_API/Concepts","locale":"en-US","native":"English (US)","sidebarHTML":"<ol><li><strong><a href=\"/en-US/docs/Web/API/WebVR_API\">WebVR API</a></strong></li><li><strong><a href=\"/en-US/docs/Web/API/WebVR_API\"><code>WebVR_API</code></a></strong></li><li class=\"toggle\"><details open=\"\"><summary>Related pages for WebVR API</summary><ol><li><a href=\"/en-US/docs/Web/API/Gamepad/displayId\"><code>Gamepad.displayId</code></a></li><li><a href=\"/en-US/docs/Web/API/Navigator/activeVRDisplays\"><code>Navigator.activeVRDisplays</code></a></li><li><a href=\"/en-US/docs/Web/API/Navigator/getVRDisplays\"><code>Navigator.getVRDisplays()</code></a></li><li><a href=\"/en-US/docs/Web/API/VRDisplay\"><code>VRDisplay</code></a></li><li><a href=\"/en-US/docs/Web/API/VRDisplayCapabilities\"><code>VRDisplayCapabilities</code></a></li><li><a href=\"/en-US/docs/Web/API/VRDisplayEvent\"><code>VRDisplayEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/VREyeParameters\"><code>VREyeParameters</code></a></li><li><a href=\"/en-US/docs/Web/API/VRFieldOfView\"><code>VRFieldOfView</code></a></li><li><a href=\"/en-US/docs/Web/API/VRFrameData\"><code>VRFrameData</code></a></li><li><a href=\"/en-US/docs/Web/API/VRLayerInit\"><code>VRLayerInit</code></a></li><li><a href=\"/en-US/docs/Web/API/VRPose\"><code>VRPose</code></a></li><li><a href=\"/en-US/docs/Web/API/VRStageParameters\"><code>VRStageParameters</code></a></li></ol></details></li></ol>","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<div class=\"notecard deprecated\" id=\"sect1\"><p><strong>Deprecated:</strong> This feature is no longer recommended. Though some browsers might still support it, it may have already been removed from the relevant web standards, may be in the process of being dropped, or may only be kept for compatibility purposes. Avoid using it, and update existing code if possible; see the <a href=\"#browser_compatibility\">compatibility table</a> at the bottom of this page to guide your decision. Be aware that this feature may cease to work at any time.</p></div>\n<div class=\"notecard note\" id=\"sect2\">\n  <p><strong>Note:</strong> WebVR API is replaced by <a href=\"/en-US/docs/Web/API/WebXR_Device_API\">WebXR API</a>. WebVR was never ratified as a standard, was implemented and enabled by default in very few browsers and supported a small number of devices.</p>\n</div>\n<p>This article discusses some of the concepts and theory behind virtual reality (VR). If you are a newcomer to the area, it is worthwhile getting an understanding of these topics before you start diving into code.</p>"}},{"type":"prose","value":{"id":"the_history_of_vr","title":"The history of VR","isH3":false,"content":"<p>Virtual reality is nothing new — the concept goes way further back than the Oculus Rift Kickstarter campaign of 2012. People have been experimenting with it for decades.</p>\n<p>In 1939 the <a href=\"https://en.wikipedia.org/wiki/View-Master\" class=\"external\" target=\"_blank\">View-Master device</a> was created, allowing people to see 3D pictures. The device displayed images stored on cardboard disks containing stereoscopic 3D pairs of small color photographs. After years of development the military got interested in using such technology, and Project Headsight was born in 1961 — this involved a helmet incorporating a video screen with a head-tracking system.</p>\n<p>There were various experiments conducted over the next few decades, but it wasn't restricted to science labs and battlefields anymore. Eventually pop culture took over with movie directors showing their visions of virtual reality. Movies like Tron (1982) and The Matrix (1999) were created, where people could transfer themselves into a whole new cyber world or were trapped in one without even knowing, accepting it as the real world.</p>\n<p>The first VR gaming attempts were big and expensive — in 1991 Virtuality Group created a VR-ready arcade machine with goggles and ported popular titles like Pac-Man to virtual reality. Sega introduced their VR glasses at the Consumer Electronics Show in 1993. Companies were experimenting, but the market and consumers weren't convinced — we had to wait until 2012 to see a real example of a successful VR project.</p>"}},{"type":"prose","value":{"id":"vr_in_recent_times","title":"VR in recent times","isH3":true,"content":"<p>So what's new? Virtual Reality hardware needs to deliver high-precision, low-latency data to deliver an acceptable user experience; computers running VR applications need to be powerful enough to handle all this information. It has not been until recently that such accuracy and power has been available at an affordable cost, if at all. Early VR prototypes cost tens of thousands of dollars, whereas more recent headsets such as the <a href=\"https://www.vive.com/uk/\" class=\"external\" target=\"_blank\">HTC VIVE</a> and <a href=\"https://www.oculus.com/rift/\" class=\"external\" target=\"_blank\">Oculus Rift</a> are available for hundreds of dollars, and cheaper solutions are available — mobile device-based solutions like <a href=\"https://www.samsung.com/global/galaxy/what-is/gear-vr/\" class=\"external\" target=\"_blank\">Gear VR</a> and <a href=\"https://arvr.google.com/cardboard/\" class=\"external\" target=\"_blank\">Google Cardboard</a>.</p>\n<p>On the software side, Valve has created <a href=\"https://store.steampowered.com/search/?category1=993\" class=\"external\" target=\"_blank\">SteamVR</a> software, which is compatible with the VIVE and other solutions, and serves to provide access to software, such as a usable VR UI.</p>\n<p>The technology itself is here, and the more expensive headsets will only get cheaper over time so more people can experience virtual reality on their own in the future.</p>"}},{"type":"prose","value":{"id":"input_devices","title":"Input devices","isH3":true,"content":"<p>Handling input for virtual reality applications is an interesting topic — it's a totally new experience for which dedicated user interfaces have to be designed. There are various approaches right now from classic keyboard and mouse, to new ones like Leap Motion and the VIVE controllers. It's a matter of trial and error to see what works in given situations and what inputs fit best for your type of game.</p>"}},{"type":"prose","value":{"id":"vr_hardware_setup","title":"VR Hardware setup","isH3":false,"content":"<p>There are two main types of setup, mobile or computer-connected. Their minimum hardware set ups are as follows:</p>\n<ul>\n  <li>Mobile: A Head-mounted display (HMD) is created using a smartphone — which acts as the VR display — mounted in a VR mount such as Google Cardboard, which contains the required lenses to provide stereoscopic vision of what is projected on the mobile screen.\n    <img src=\"/en-US/docs/Web/API/WebVR_API/Concepts/mobilebasedvrsetup.png\" alt=\"Mobile based VR setup\" width=\"1280\" height=\"400\" loading=\"lazy\">\n  </li>\n  <li>Computer-connected: A VR setup is connected to your computer — this consists of a Head Mounted Display (HMD) containing a high resolution landscape-oriented screen onto which the visuals for both the left and right eye are displayed, which also includes a lens for each eye to promote separation of the left and right eye scene (stereoscopic vision.) The setup also includes a separate position sensor that works out the position/orientation/velocity/acceleration of your head and constantly passes that information the computer. \n    <img src=\"/en-US/docs/Web/API/WebVR_API/Concepts/computerbasedvrsetup.png\" alt=\"Computer based VR Setup\" width=\"1280\" height=\"500\" loading=\"lazy\">\n  </li>\n</ul>\n<div class=\"notecard note\" id=\"sect3\">\n  <p><strong>Note:</strong> Computer-connected systems sometimes don't include a position sensor, but they usually do.</p>\n</div>\n<p>Other hardware that complements the VR experience includes:</p>\n<ul>\n  <li><strong>A hand recognition sensor</strong>: A sensor that tracks the position and movement of your hand, allowing it to become an interesting controller, and an object in VR gameworlds. The most advanced to date is the <a href=\"https://www.ultraleap.com/\" class=\"external\" target=\"_blank\">Leap Motion</a>, which works with the computer (connected to the Oculus Rift) and can also work connected to a mobile device (the latter is in an experimental phase.)</li>\n  <li><strong>A gamepad</strong>: We can configure an XBox controller or similar to work as a keyboard in the browser — this offers further possibilities of interaction with a VR webpage. There are some gamepads that work with a mobile setup but these are connected via Bluetooth so don't work with WebVR.</li>\n  <li><strong>An eye tracking sensor (experimental)</strong>: The FOVE project is the first headset that reads subtle eye movements.</li>\n  <li><strong>A facial expression tracker (experimental)</strong>: Researchers at the University of Southern California and Facebook's Oculus division have been testing new ways of tracking facial expressions and transferring them to a virtual character.</li>\n  <li><strong>A more complex positional sensor system</strong>: As an example, the HTC VIVE features two position sensors that sit in opposite corners of a space, mapping it all out and allowing VR experiences to be enjoyed in spaces of up to 5m x 5m.</li>\n</ul>"}},{"type":"prose","value":{"id":"position_and_orientation_velocity_and_acceleration","title":"Position and orientation, velocity and acceleration","isH3":false,"content":"<p>As mentioned above, the position sensor detects information concerning the HMD and constantly outputs it, allowing you to continually update a scene according to head movement, rotation, etc. But what exactly is the information?</p>\n<p>\n  <img src=\"/en-US/docs/Web/API/WebVR_API/Concepts/positionorientationvr.png\" alt=\"Position and Orientation VR setup\" width=\"1280\" height=\"500\" loading=\"lazy\">\n</p>\n<p>The output information falls into four categories:</p>\n<ol>\n  <li>Position — The position of the HMD along three axes in a 3D coordinate space. x is to the left and right, y is up and down, and z is towards and away from the position sensor. In WebVR, the x, y, and z coordinates are represented by the array contained in <a href=\"/en-US/docs/Web/API/VRPose/position\"><code>VRPose.position</code></a>.</li>\n  <li>Orientation — The rotation of the HMD around three axes in a 3D coordinate space. Pitch is rotation around the x axis, yaw is rotation around the y axis, and roll is rotation around the z axis. In WebVR, the pitch, yaw, and roll are represented by the first three elements of the array contained in <a href=\"/en-US/docs/Web/API/VRPose/orientation\"><code>VRPose.orientation</code></a>.</li>\n  <li>Velocity — There are two types of velocity to consider in VR:\n    <ul>\n      <li>Linear — The speed along any one of the axes that the HMD is traveling. This information can be accessed using <a href=\"/en-US/docs/Web/API/VRPose/linearVelocity\"><code>VRPose.linearVelocity</code></a>.</li>\n      <li>Angular — The speed at which the HMD is rotating around any one of the axes. This information can be accessed using <a href=\"/en-US/docs/Web/API/VRPose/angularVelocity\"><code>VRPose.angularVelocity</code></a>.</li>\n    </ul>\n  </li>\n  <li>Acceleration — There are two types of acceleration to consider in VR:\n    <ul>\n      <li>Linear — The acceleration of travel along any one of the axes that the HMD is traveling. This information can be accessed using <a href=\"/en-US/docs/Web/API/VRPose/linearAcceleration\"><code>VRPose.linearAcceleration</code></a>.</li>\n      <li>Angular — The acceleration of rotation of the HMD around any one of the axes. This information can be accessed using <a href=\"/en-US/docs/Web/API/VRPose/angularAcceleration\"><code>VRPose.angularAcceleration</code></a>.</li>\n    </ul>\n  </li>\n</ol>"}},{"type":"prose","value":{"id":"field_of_view","title":"Field of view","isH3":false,"content":"<p>The field of view (FOV) is the area that each of the user's eyes can reasonably be expected to see. It roughly takes the form of a pyramid shape, laid down on one side, with the apex inside the user's head, and the rest of the pyramid emanating from the user's eye. Each eye has its own FOV, one slightly overlapping the other.</p>\n<p>\n  <img src=\"/en-US/docs/Web/API/WebVR_API/Concepts/fovrelatedproperties.png\" alt=\"FOV related properties\" width=\"1280\" height=\"500\" loading=\"lazy\">\n</p>\n<p>The FOV is defined by the following values:</p>\n<ul>\n  <li><a href=\"/en-US/docs/Web/API/VRFieldOfView/upDegrees\"><code>VRFieldOfView.upDegrees</code></a>: The number of degrees upwards that the field of view extends in.</li>\n  <li><a href=\"/en-US/docs/Web/API/VRFieldOfView/rightDegrees\"><code>VRFieldOfView.rightDegrees</code></a>: The number of degrees to the right that the field of view extends in.</li>\n  <li><a href=\"/en-US/docs/Web/API/VRFieldOfView/downDegrees\"><code>VRFieldOfView.downDegrees</code></a>: The number of degrees downwards that the field of view extends in.</li>\n  <li><a href=\"/en-US/docs/Web/API/VRFieldOfView/leftDegrees\"><code>VRFieldOfView.leftDegrees</code></a>: The number of degrees to the left that the field of view extends in.</li>\n  <li>zNear, defined by <a href=\"/en-US/docs/Web/API/VRDisplay/depthNear\"><code>VRDisplay.depthNear</code></a>: The distance from the middle of the user's head to the start of the visible FOV.</li>\n  <li>zFar, defined by <a href=\"/en-US/docs/Web/API/VRDisplay/depthFar\"><code>VRDisplay.depthFar</code></a>: The distance from the middle of the user's head to the end of the visible FOV.</li>\n</ul>\n<p>The default values for these properties will differ slightly by VR hardware, although they tend to be around 53° up and down, and 47° left and right, with zNear and zFar coming in at around 0.1m and 10000m respectively.</p>\n<div class=\"notecard note\" id=\"sect4\">\n  <p><strong>Note:</strong> The user can potentially see all the way around them, which is a brand new concept for apps and games. Try to give people a reason to look around and see what's behind them — make them reach out and find things that are not visible at the very beginning. Describe what's behind their backs.</p>\n</div>"}},{"type":"prose","value":{"id":"concepts_for_vr_apps","title":"Concepts for VR apps","isH3":false,"content":"<p>This section discusses concepts to be aware of when developing VR apps that you've probably not had to consider before when developing regular apps for mobile or desktop.</p>"}},{"type":"prose","value":{"id":"stereoscopic_vision","title":"Stereoscopic vision","isH3":true,"content":"<p>Stereoscopic vision is the normal vision humans and (most) animals have — the perception of two slightly differing images (one from each eye) as a single image. This results in depth perception, helping us to see the world in glorious 3D. To recreate this in VR apps, you need to render two very slightly different views side by side, which will be taken in by the left and right eyes when the user is using the HMD.</p>\n<p>\n  <img src=\"/en-US/docs/Web/API/WebVR_API/Concepts/createstereoscopicimages.png\" alt=\"How to create stereoscopic 3D images\" width=\"1280\" height=\"500\" loading=\"lazy\">\n</p>"}},{"type":"prose","value":{"id":"head_tracking","title":"Head tracking","isH3":true,"content":"<p>\n  The primary technology used to make you feel present in a 360º scene, thanks to the gyroscope, accelerometer, and magnetometer (compass) included in the HMD.\n  It has primary relevance because it makes our eyes believe we are in front of a spherical screen, giving users realistic immersion inside the app canvas.\n</p>"}},{"type":"prose","value":{"id":"eye_strain","title":"Eye strain","isH3":true,"content":"<p>A term commonly used in VR because it is a major handicap of using an HMD — we are constantly fooling the eye with what we are showing in the app canvas, and this leads to the eyes doing a lot more work than they normally would, so using VR apps for any extended period of time can lead to eye strain.</p>\n<p>To minimize this unwanted effect, we need to:</p>\n<ul>\n  <li>Avoid focusing on different depths (e.g. avoid using a lot of particles with different depths.)</li>\n  <li>Avoid eye convergence (e.g. if you have an object that comes towards the camera your eyes will follow and converge on it.)</li>\n  <li>Use darker backgrounds with more subdued colors where possible; a bright screen will make the eyes more tired.</li>\n  <li>Avoid rapid brightness changes.</li>\n  <li>Avoid presenting the user with large amounts of text to read. You should also be careful with the distance between the eyes/camera and the text to read. 0.5m is uncomfortable, whereas at more than 2m the stereo effect starts to break down, so somewhere in between is advisable.</li>\n  <li>Be careful with the distance between objects and the camera in general. Oculus recommends 0.75m as a minimum distance of focus.</li>\n  <li>Use a pointer if the user needs to interact with an object in the scene — this will help them point to it correctly with less effort.</li>\n</ul>\n<p>In general, the path of least visual effort will give the user a less tiring experience.</p>"}},{"type":"prose","value":{"id":"motion_sickness","title":"Motion sickness","isH3":true,"content":"<p>If developers do not take utmost care, VR apps can actually cause their users to feel sick. This effect is produced when the stimuli their eyes are receiving is not what the body expects to receive.</p>\n<p>To avoid bringing on motion sickness in our users (or at least minimize the effects), we need to:</p>\n<ul>\n  <li>Always maintain head tracking (this is the most important of all, especially if it occurs in middle of the experience.)</li>\n  <li>Use constant velocity; avoid acceleration or deceleration camera movements (use linear acceleration, and avoid easing if you can.)</li>\n  <li>Keep the frame rate up (less than 30fps is uncomfortable.)</li>\n  <li>Avoid sharp and/or unexpected camera rotations.</li>\n  <li>Add fixed points of reference for fixed objects (otherwise the user will believe they are on the move.)</li>\n  <li>Do not use Depth of Field or Motion Blur post processing because you do not know where the eyes will focus.</li>\n  <li>Avoid brightness changes (use low frequency textures or fog effects to create smooth lighting transitions).</li>\n</ul>\n<p>Overall your eyes should not send signals to the brain that cause reflex actions in other parts of the body.</p>"}},{"type":"prose","value":{"id":"latency","title":"Latency","isH3":true,"content":"<p>Latency is the time between the physical head movement and the visual display reaching the user's eyes from the screen of an HMD being updated. This is one of the most critical factors in providing a realistic experience. Humans can detect very small delays — we need to keep the latency below 20 milliseconds if they are to be imperceptible (for example a 60Hz monitor has a 16 ms response.)</p>\n<p>The Oculus Rift headset has a latency of 20 ms or less, but with mobile device-based setups it will depend heavily on the smartphone CPU power and other capabilities.</p>"}},{"type":"prose","value":{"id":"frame_rate_frames_per_second_fps","title":"Frame rate (Frames per second / FPS)","isH3":true,"content":"<p>Based on the Wikipedia definition, frame rate is the frequency at which an imaging device produces unique consecutive images, called frames. A rate of 60fps is an acceptable rate for a smooth user experience, but depending on the performance of the machine the app is running on, or the complexity of the content you want to show, it can drastically lower. Less than 30fps is generally considered jittery, and annoying to the user.</p>\n<p>One of the most difficult tasks is to maintain a constant and high frame rate value, so we must optimize our code to make it as efficient as possible. It is preferable to have a decent frame rate that doesn't constantly or suddenly change; for this you need to as few necessary objects moving into the scene as possible and (in the case of WebGL) try to reduce draw calls.</p>"}},{"type":"prose","value":{"id":"interpupillary_distance_ipd","title":"Interpupillary distance (IPD)","isH3":true,"content":"<p>Based on the Wikipedia definition, IPD is the distance between the centers of the pupils of the two eyes. IPD is critical for the design of binocular viewing systems, where both eye pupils need to be positioned within the exit pupils of the viewing system.</p>\n<p>Interpupillary distance (IPD) can be calculated using <a href=\"/en-US/docs/Web/API/VREyeParameters/offset\"><code>VREyeParameters.offset</code></a> in WebVR, which is equal to half the IPD.</p>\n<p>This value is returned by the HMD and its value may be around 60 to 70 mm; in the case of some HMDs like Oculus Rift's, you can set your own IPD. Normally we don't change this value but you can play with it to change the scale of the entire scene. For example, if your IPD is set to 6000 mm, the user would view the scene like a giant looking at a Lilliputian world.</p>"}},{"type":"prose","value":{"id":"degrees_of_freedom_dof","title":"Degrees of Freedom (DoF)","isH3":true,"content":"<p>DoF refers to the movement of a rigid body inside space. There is no uniformity in creating acronyms for this term — we can find references to 3DoF in the context of sensors that detect only rotational head tracking, and 6DoF when an input allows us to control position and orientation simultaneously. We even sometimes find 9DoF references when the hardware contains three sensors like gyroscope, accelerometer and magnetometer, but the results of the 3 x 3DoF values will actually return a 6 degrees of freedom tracking.</p>\n<p>DoF is directly related to the tracking of the user's head movement.</p>"}},{"type":"prose","value":{"id":"cone_of_focus","title":"Cone of focus","isH3":true,"content":"<p>Although our field of view is much larger (approximately 180º), we need to be aware that only in a small portion of that field can you perceive symbols (the center 60º) or read text (the center 10º). If you do not have an eye tracking sensor we assume that the center of the screen is where the user is focusing their eyes.</p>\n<p>This limitation is important to consider when deciding where to place visuals on the app canvas — too far toward the edge of the cone of focus can lead to eye strain much more quickly. There is a very interesting post about this (amongst other things) at <a href=\"https://mixedreality.mozilla.org/%3E\" class=\"external\" target=\"_blank\">Mozilla's Mixed Reality site</a> — in particular, read <a href=\"https://blog.mozvr.com/quick-vr-prototypes/\" class=\"external\" target=\"_blank\">Quick VR Mockups with Illustrator</a>.</p>"}},{"type":"prose","value":{"id":"3d_positional_audio","title":"3D Positional Audio","isH3":true,"content":"<p>3D positional audio refers to a group of effects that manipulate audio to simulate how it would sound in a three dimensional space.</p>\n<p>This directly related to the <a href=\"/en-US/docs/Web/API/Web_Audio_API\">Web Audio API</a>, which allows us to place sounds on objects we have in the canvas or launch audio depending on the part of the scene the user is traveling towards or looking at.</p>"}}],"toc":[{"text":"The history of VR","id":"the_history_of_vr"},{"text":"VR Hardware setup","id":"vr_hardware_setup"},{"text":"Position and orientation, velocity and acceleration","id":"position_and_orientation_velocity_and_acceleration"},{"text":"Field of view","id":"field_of_view"},{"text":"Concepts for VR apps","id":"concepts_for_vr_apps"}],"summary":"This article discusses some of the concepts and theory behind virtual reality (VR). If you are a newcomer to the area, it is worthwhile getting an understanding of these topics before you start diving into code.","popularity":0,"modified":"2023-01-09T02:31:42.000Z","other_translations":[{"title":"WebVR の概要","locale":"ja","native":"日本語"},{"title":"WebVR concepts","locale":"zh-CN","native":"中文 (简体)"}],"source":{"folder":"en-us/web/api/webvr_api/concepts","github_url":"https://github.com/mdn/content/blob/main/files/en-us/web/api/webvr_api/concepts/index.md","last_commit_url":"https://github.com/mdn/content/commit/13dc8d707abd26319eba06d9c48630eb25e9adb9","filename":"index.md"},"short_title":"WebVR concepts","parents":[{"uri":"/en-US/docs/Web","title":"References"},{"uri":"/en-US/docs/Web/API","title":"Web APIs"},{"uri":"/en-US/docs/Web/API/WebVR_API","title":"WebVR API"},{"uri":"/en-US/docs/Web/API/WebVR_API/Concepts","title":"WebVR concepts"}],"pageTitle":"WebVR concepts - Web APIs | MDN","noIndexing":false}}</script>
<!-- Mirrored from developer.mozilla.org/en-US/docs/Web/API/WebVR_API/Concepts by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 14 Feb 2023 04:50:09 GMT -->
</body></html>