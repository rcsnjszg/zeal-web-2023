<html><!-- Mirrored from developer.mozilla.org/en-US/docs/Web/API/WebXR_Device_API/Fundamentals by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 14 Feb 2023 04:50:14 GMT --><!-- Added by HTTrack --><head><meta http-equiv="content-type" content="text/html;charset=utf-8"><!-- /Added by HTTrack -->
<meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" href="../../../../../favicon-48x48.cbbd161b.png"><link rel="apple-touch-icon" href="../../../../../apple-touch-icon.6803c6f0.png"><meta name="theme-color" content="#ffffff"><link rel="manifest" href="../../../../../manifest.56b1cedc.json"><link rel="search" type="application/opensearchdescription+xml" href="https://developer.mozilla.org/opensearch.xml" title="MDN Web Docs"><title>Fundamentals of WebXR</title><link rel="alternate" title="WebXR の基礎" href="https://developer.mozilla.org/ja/docs/Web/API/WebXR_Device_API/Fundamentals" hreflang="ja"><link rel="alternate" title="Fundamentals of WebXR" href="Fundamentals.html" hreflang="en"><meta name="robots" content="index, follow"><meta name="description" content="WebXR, with the WebXR Device API at its core, provides the functionality needed to bring both augmented and virtual reality (AR and VR) to the web. Together, these technologies are referred to as mixed reality (MR) or cross reality (XR). Mixed reality is a large and complex subject, with much to learn and many other APIs to bring together to create an engaging experience for users."><meta property="og:url" content="Fundamentals.html"><meta property="og:title" content="Fundamentals of WebXR - Web APIs | MDN"><meta property="og:locale" content="en-US"><meta property="og:description" content="WebXR, with the WebXR Device API at its core, provides the functionality needed to bring both augmented and virtual reality (AR and VR) to the web. Together, these technologies are referred to as mixed reality (MR) or cross reality (XR). Mixed reality is a large and complex subject, with much to learn and many other APIs to bring together to create an engaging experience for users."><meta property="og:image" content="../../../../../mdn-social-share.cd6c4a5a.png"><meta property="twitter:card" content="summary_large_image"><link rel="canonical" href="Fundamentals.html"><style media="print">.article-actions-container,.document-toc-container,.language-menu,.main-menu-toggle,.mdn-cta-container,.on-github,.page-footer,.sidebar,.top-navigation-main,ul.prev-next{display:none!important}.main-page-content,.main-page-content pre{padding:2px}.main-page-content pre{border-left-width:2px}</style><script src="../../../../../static/js/ga.js" defer=""></script><script defer="defer" src="../../../../../static/js/main.5c9d40d0.js"></script><link href="../../../../../static/css/main.7d378400.css" rel="stylesheet"></head><body><script>document.body.addEventListener("load",(t=>{t.target.classList.contains("interactive")&&t.target.setAttribute("data-readystate","complete")}),{capture:!0});const c={light:"#ffffff",dark:"#1b1b1b"};if(window&&document.documentElement)try{const t=window.localStorage.getItem("theme");t&&(document.documentElement.className=t,document.documentElement.style.backgroundColor=c[t])}catch(t){console.warn("Unable to read theme from localStorage",t)}</script><div id="root"><ul id="nav-access" class="a11y-nav"><li><a id="skip-main" href="#content">Skip to main content</a></li><li><a id="skip-search" href="#top-nav-search-input">Skip to search</a></li><li><a id="skip-select-language" href="#languages-switcher-button">Skip to select language</a></li></ul><div class="page-wrapper  category-api document-page"><div class="main-document-header-container"><header class="main-document-header-container top-navigation 
      
      "><div class="container "><div class="top-navigation-wrap"><a href="https://developer.mozilla.org/en-US/" class="logo" aria-label="MDN homepage"><svg id="mdn-docs-logo" xmlns="http://www.w3.org/2000/svg" x="0" y="0" viewBox="0 0 694.9 104.4" style="enable-background:new 0 0 694.9 104.4" xml:space="preserve" role="img"><title>MDN Web Docs</title><style>.logo-m{fill:var(--text-link)}</style><g class="logo-m"><path d="M40.3 0 11.7 92.1H0L28.5 0h11.8zM50.7 0v92.1H40.3V0h10.4zM91 0 62.5 92.1H50.8L79.3 0H91zM101.4 0v92.1H91V0h10.4z"></path></g><path class="logo-m" d="M627.9 95.6h67v8.8h-67v-8.8z"></path><g style="fill:var(--text-primary)"><path d="M367 42h-4l-10.7 30.8h-5.5l-10.8-26h-.4l-10.5 26h-5.2L308.7 42h-3.8v-5.6H323V42h-6.5l6.8 20.4h.4l10.3-26h4.7l11.2 26h.5l5.7-20.3h-6.2v-5.6H367V42zM401.9 62c-.4 3.2-2 5.9-4.7 8.2-2.8 2.3-6.5 3.4-11.3 3.4-5.4 0-9.7-1.6-13.1-4.7-3.3-3.2-5-7.7-5-13.7 0-5.7 1.6-10.3 4.7-14s7.4-5.5 12.9-5.5c5.1 0 9.1 1.6 11.9 4.7s4.3 6.9 4.3 11.3c0 1.5-.2 3-.5 4.7h-25.6c.3 7.7 4 11.6 10.9 11.6 2.9 0 5.1-.7 6.5-2 1.5-1.4 2.5-3 3-4.9l6 .9zM394 51.3c.2-2.4-.4-4.7-1.8-6.9s-3.8-3.3-7-3.3c-3.1 0-5.3 1-6.9 3-1.5 2-2.5 4.4-2.8 7.2H394zM445 53.7c0 5-1.3 9.5-4 13.7s-6.9 6.2-12.7 6.2c-6 0-10.3-2.2-12.7-6.7-.1.4-.2 1.4-.4 2.9s-.3 2.5-.4 2.9h-7.3c.3-1.7.6-3.5.8-5.3.3-1.8.4-3.7.4-5.5V22.3h-6v-5.6H416v27c1.1-2.2 2.7-4.1 4.7-5.7 2-1.6 4.8-2.4 8.4-2.4 4.6 0 8.4 1.6 11.4 4.7 3 3.2 4.5 7.6 4.5 13.4zm-7.7.6c0-4.2-1-7.4-3-9.5-2-2.2-4.4-3.3-7.4-3.3-3.4 0-6 1.2-8 3.7-1.9 2.4-2.9 5-3 7.7V57c0 3 1 5.6 3 7.7s4.5 3.1 7.6 3.1c3.6 0 6.3-1.3 8.1-3.9 1.8-2.7 2.7-5.9 2.7-9.6zM506.5 72.8h-13.2v-7.2c-1.2 2.2-2.8 4.1-4.9 5.6-2.1 1.6-4.8 2.4-8.3 2.4-4.8 0-8.7-1.6-11.6-4.9-2.9-3.2-4.3-7.7-4.3-13.3 0-5 1.3-9.6 4-13.7 2.6-4.1 6.9-6.2 12.8-6.2 5.7 0 9.8 2.2 12.3 6.5V22.3h-8.6v-5.6h15.8v50.6h6v5.5zM493.2 56v-4.4c-.1-3-1.2-5.5-3.2-7.3s-4.4-2.8-7.2-2.8c-3.6 0-6.3 1.3-8.2 3.9-1.9 2.6-2.8 5.8-2.8 9.6 0 4.1 1 7.3 3 9.5s4.5 3.3 7.4 3.3c3.2 0 5.8-1.3 7.8-3.8 2.1-2.6 3.1-5.3 3.2-8zM546.3 54.6c0 5.6-1.8 10.2-5.3 13.7s-8.2 5.3-13.9 5.3-10.1-1.7-13.4-5.1c-3.3-3.4-5-7.9-5-13.5 0-5.3 1.6-9.9 4.7-13.7 3.2-3.8 7.9-5.7 14.2-5.7s11 1.9 14.1 5.7c3 3.7 4.6 8.1 4.6 13.3zm-7.7-.2c0-4-1-7.2-3-9.5s-4.8-3.5-8.2-3.5c-3.6 0-6.4 1.2-8.3 3.7s-2.9 5.6-2.9 9.5c0 3.7.9 6.8 2.8 9.4 1.9 2.6 4.6 3.9 8.3 3.9 3.6 0 6.4-1.3 8.4-3.8 1.9-2.6 2.9-5.8 2.9-9.7zM583.6 60.2c-.4 3.2-1.9 6.3-4.4 9.1-2.5 2.9-6.4 4.3-11.8 4.3-5.2 0-9.4-1.6-12.6-4.8-3.2-3.2-4.8-7.7-4.8-13.7 0-5.5 1.6-10.1 4.7-13.9 3.2-3.8 7.6-5.7 13.2-5.7 2.3 0 4.6.3 6.7.8 2.2.5 4.2 1.5 6.2 2.9l1.5 9.5-5.9.7-1.3-6.1c-2.1-1.2-4.5-1.8-7.2-1.8-3.5 0-6.1 1.2-7.7 3.7-1.7 2.5-2.5 5.7-2.5 9.6 0 4.1.9 7.3 2.7 9.5 1.8 2.3 4.4 3.4 7.8 3.4 5.2 0 8.2-2.9 9.2-8.8l6.2 1.3zM618.3 62.1c0 3.6-1.5 6.5-4.6 8.5s-7 3-11.7 3c-5.7 0-10.6-1.2-14.6-3.6l1.2-8.8 5.7.6-.2 4.7c1.1.5 2.3.9 3.6 1.1s2.6.3 3.9.3c2.4 0 4.5-.4 6.5-1.3 1.9-.9 2.9-2.2 2.9-4.1 0-1.8-.8-3.1-2.3-3.8s-3.5-1.3-5.8-1.7-4.6-.9-6.9-1.4c-2.3-.6-4.2-1.6-5.7-2.9-1.6-1.4-2.3-3.5-2.3-6.3 0-4.1 1.5-6.9 4.6-8.5s6.4-2.4 9.9-2.4c2.6 0 5 .3 7.2.9 2.2.6 4.3 1.4 6.1 2.4l.8 8.8-5.8.7-.8-5.7c-2.3-1-4.7-1.6-7.2-1.6-2.1 0-3.7.4-5.1 1.1-1.3.8-2 2-2 3.8 0 1.7.8 2.9 2.3 3.6 1.5.7 3.4 1.2 5.7 1.6 2.2.4 4.5.8 6.7 1.4 2.2.6 4.1 1.6 5.7 3 1.4 1.6 2.2 3.7 2.2 6.6zM197.6 73.2h-17.1v-5.5h3.8V51.9c0-3.7-.7-6.3-2.1-7.9-1.4-1.6-3.3-2.3-5.7-2.3-3.2 0-5.6 1.1-7.2 3.4s-2.4 4.6-2.5 6.9v15.6h6v5.5h-17.1v-5.5h3.8V51.9c0-3.8-.7-6.4-2.1-7.9-1.4-1.5-3.3-2.3-5.6-2.3-3.2 0-5.5 1.1-7.2 3.3-1.6 2.2-2.4 4.5-2.5 6.9v15.8h6.9v5.5h-20.2v-5.5h6V42.4h-6.1v-5.6h13.4v6.4c1.2-2.1 2.7-3.8 4.7-5.2 2-1.3 4.4-2 7.3-2s5.3.7 7.5 2.1c2.2 1.4 3.7 3.5 4.5 6.4 1.1-2.5 2.7-4.5 4.9-6.1s4.8-2.4 7.9-2.4c3.5 0 6.5 1.1 8.9 3.3s3.7 5.6 3.7 10.2v18.2h6.1v5.5zm42.5 0h-13.2V66c-1.2 2.2-2.8 4.1-4.9 5.6-2.1 1.6-4.8 2.4-8.3 2.4-4.8 0-8.7-1.6-11.6-4.9-2.9-3.2-4.3-7.7-4.3-13.3 0-5 1.3-9.6 4-13.7 2.6-4.1 6.9-6.2 12.8-6.2s9.8 2.2 12.3 6.5V22.7h-8.6v-5.6h15.8v50.6h6v5.5zm-13.3-16.8V52c-.1-3-1.2-5.5-3.2-7.3s-4.4-2.8-7.2-2.8c-3.6 0-6.3 1.3-8.2 3.9-1.9 2.6-2.8 5.8-2.8 9.6 0 4.1 1 7.3 3 9.5s4.5 3.3 7.4 3.3c3.2 0 5.8-1.3 7.8-3.8 2.1-2.6 3.1-5.3 3.2-8zm61.5 16.8H269v-5.5h6V51.9c0-3.7-.7-6.3-2.2-7.9-1.4-1.6-3.4-2.3-5.7-2.3-3.1 0-5.6 1-7.4 3s-2.8 4.4-2.9 7v15.9h6v5.5h-19.3v-5.5h6V42.4h-6.2v-5.6h13.6V43c2.6-4.6 6.8-6.9 12.7-6.9 3.6 0 6.7 1.1 9.2 3.3s3.7 5.6 3.7 10.2v18.2h6v5.4h-.2z"></path></g></svg></a><button title="Open main menu" type="button" class="button action has-icon main-menu-toggle" aria-haspopup="menu" aria-label="Open main menu" aria-expanded="false"><span class="button-wrap"><span class="icon icon-menu "></span><span class="visually-hidden">Open main menu</span></span></button></div><div class="top-navigation-main"><nav class="main-nav" aria-label="Main menu"><ul class="main-menu nojs"><li class="top-level-entry-container"><button type="button" id="references-button" class="top-level-entry menu-toggle" aria-controls="references-menu" aria-expanded="false">References</button><a href="https://developer.mozilla.org/en-US/docs/Web" class="top-level-entry">References</a><ul id="references-menu" class="submenu references hidden inline-submenu-lg" aria-labelledby="references-button"><li class="apis-link-container mobile-only "><a href="https://developer.mozilla.org/en-US/docs/Web" class="submenu-item "><div class="submenu-icon"></div><div class="submenu-content-container"><div class="submenu-item-heading">Overview / Web Technology</div><p class="submenu-item-description">Web technology reference for developers</p></div></a></li><li class="html-link-container "><a href="https://developer.mozilla.org/en-US/docs/Web/HTML" class="submenu-item "><div class="submenu-icon html"></div><div class="submenu-content-container"><div class="submenu-item-heading">HTML</div><p class="submenu-item-description">Structure of content on the web</p></div></a></li><li class="css-link-container "><a href="https://developer.mozilla.org/en-US/docs/Web/CSS" class="submenu-item "><div class="submenu-icon css"></div><div class="submenu-content-container"><div class="submenu-item-heading">CSS</div><p class="submenu-item-description">Code used to describe document style</p></div></a></li><li class="javascript-link-container "><a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript" class="submenu-item "><div class="submenu-icon javascript"></div><div class="submenu-content-container"><div class="submenu-item-heading">JavaScript</div><p class="submenu-item-description">General-purpose scripting language</p></div></a></li><li class="http-link-container "><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP" class="submenu-item "><div class="submenu-icon http"></div><div class="submenu-content-container"><div class="submenu-item-heading">HTTP</div><p class="submenu-item-description">Protocol for transmitting web resources</p></div></a></li><li class="apis-link-container "><a href="../../API.html" class="submenu-item "><div class="submenu-icon apis"></div><div class="submenu-content-container"><div class="submenu-item-heading">Web APIs</div><p class="submenu-item-description">Interfaces for building web applications</p></div></a></li><li class="apis-link-container "><a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions" class="submenu-item "><div class="submenu-icon"></div><div class="submenu-content-container"><div class="submenu-item-heading">Web Extensions</div><p class="submenu-item-description">Developing extensions for web browsers</p></div></a></li><li class="apis-link-container desktop-only "><a href="https://developer.mozilla.org/en-US/docs/Web" class="submenu-item "><div class="submenu-icon"></div><div class="submenu-content-container"><div class="submenu-item-heading">Web Technology</div><p class="submenu-item-description">Web technology reference for developers</p></div></a></li></ul></li><li class="top-level-entry-container"><button type="button" id="guides-button" class="top-level-entry menu-toggle" aria-controls="guides-menu" aria-expanded="false">Guides</button><a href="https://developer.mozilla.org/en-US/docs/Learn" class="top-level-entry">Guides</a><ul id="guides-menu" class="submenu guides hidden inline-submenu-lg" aria-labelledby="guides-button"><li class="apis-link-container mobile-only "><a href="https://developer.mozilla.org/en-US/docs/Learn" class="submenu-item "><div class="submenu-icon learn"></div><div class="submenu-content-container"><div class="submenu-item-heading">Overview / MDN Learning Area</div><p class="submenu-item-description">Learn web development</p></div></a></li><li class="apis-link-container desktop-only "><a href="https://developer.mozilla.org/en-US/docs/Learn" class="submenu-item "><div class="submenu-icon learn"></div><div class="submenu-content-container"><div class="submenu-item-heading">MDN Learning Area</div><p class="submenu-item-description">Learn web development</p></div></a></li><li class="html-link-container "><a href="https://developer.mozilla.org/en-US/docs/Learn/HTML" class="submenu-item "><div class="submenu-icon html"></div><div class="submenu-content-container"><div class="submenu-item-heading">HTML</div><p class="submenu-item-description">Learn to structure web content with HTML</p></div></a></li><li class="css-link-container "><a href="https://developer.mozilla.org/en-US/docs/Learn/CSS" class="submenu-item "><div class="submenu-icon css"></div><div class="submenu-content-container"><div class="submenu-item-heading">CSS</div><p class="submenu-item-description">Learn to style content using CSS</p></div></a></li><li class="javascript-link-container "><a href="https://developer.mozilla.org/en-US/docs/Learn/JavaScript" class="submenu-item "><div class="submenu-icon javascript"></div><div class="submenu-content-container"><div class="submenu-item-heading">JavaScript</div><p class="submenu-item-description">Learn to run scripts in the browser</p></div></a></li><li class=" "><a href="https://developer.mozilla.org/en-US/docs/Web/Accessibility" class="submenu-item "><div class="submenu-icon"></div><div class="submenu-content-container"><div class="submenu-item-heading">Accessibility</div><p class="submenu-item-description">Learn to make the web accessible to all</p></div></a></li></ul></li><li class="top-level-entry-container"><button type="button" id="mdn-plus-button" class="top-level-entry menu-toggle" aria-controls="mdn-plus-menu" aria-expanded="false">MDN Plus</button><a href="https://developer.mozilla.org/en-US/plus" class="top-level-entry">MDN Plus</a><ul id="mdn-plus-menu" class="submenu mdn-plus hidden inline-submenu-lg" aria-labelledby="mdn-plus-button"><li class=" "><a href="https://developer.mozilla.org/en-US/plus" class="submenu-item "><div class="submenu-icon"></div><div class="submenu-content-container"><div class="submenu-item-heading">Overview</div><p class="submenu-item-description">A customized MDN experience</p></div></a></li><li class=" "><a href="https://developer.mozilla.org/en-US/plus/updates" class="submenu-item "><div class="submenu-icon"></div><div class="submenu-content-container"><div class="submenu-item-heading">Updates</div><p class="submenu-item-description">All browser compatibility updates at a glance</p></div></a></li><li class=" "><a href="https://developer.mozilla.org/en-US/plus/docs/features/overview" class="submenu-item "><div class="submenu-icon"></div><div class="submenu-content-container"><div class="submenu-item-heading">Documentation</div><p class="submenu-item-description">Learn how to use MDN Plus</p></div></a></li><li class=" "><a href="https://developer.mozilla.org/en-US/plus/docs/faq" class="submenu-item "><div class="submenu-icon"></div><div class="submenu-content-container"><div class="submenu-item-heading">FAQ</div><p class="submenu-item-description">Frequently asked questions about MDN Plus</p></div></a></li></ul></li></ul></nav><div class="header-search"><form action="https://developer.mozilla.org/en-US/search" role="search" aria-haspopup="listbox" aria-owns="top-nav-search-menu" aria-expanded="false" class="search-form search-widget" id="top-nav-search-form"><label id="top-nav-search-label" for="top-nav-search-input" class="visually-hidden">Search MDN</label><input id="top-nav-search-input" aria-autocomplete="list" aria-controls="top-nav-search-menu" aria-labelledby="top-nav-search-label" autocomplete="off" type="search" class="search-input-field" name="q" placeholder="   " required="" value=""><button type="button" class="button action has-icon clear-search-button"><span class="button-wrap"><span class="icon icon-cancel "></span><span class="visually-hidden">Clear search input</span></span></button><button type="submit" class="button action has-icon search-button"><span class="button-wrap"><span class="icon icon-search "></span><span class="visually-hidden">Search</span></span></button><div id="top-nav-search-menu" role="listbox" aria-labelledby="top-nav-search-label"></div></form></div><div class="theme-switcher-menu"><button type="button" class="button action has-icon theme-switcher-menu small" aria-haspopup="menu"><span class="button-wrap"><span class="icon icon-theme-os-default "></span>Theme</span></button></div><ul class="auth-container"><li><a href="https://developer.mozilla.org/users/fxa/login/authenticate/?next=%2Fen-US%2Fdocs%2FWeb%2FAPI%2FWebXR_Device_API%2FFundamentals" class="signin-link" rel="nofollow">Already a subscriber?</a></li><li><a class="button primary mdn-plus-subscribe-link" href="https://developer.mozilla.org/en-US/plus"><span class="button-wrap">Get MDN Plus</span></a></li></ul></div></div></header><div class="article-actions-container"><div class="container"><button type="button" class="button action has-icon sidebar-button" aria-label="Expand sidebar" aria-expanded="false" aria-controls="sidebar-quicklinks"><span class="button-wrap"><span class="icon icon-sidebar "></span></span></button><nav class="breadcrumbs-container" aria-label="Breadcrumb"><ol typeof="BreadcrumbList" vocab="https://schema.org/" aria-label="breadcrumbs"><li property="itemListElement" typeof="ListItem"><a class="breadcrumb" property="item" typeof="WebPage" href="https://developer.mozilla.org/en-US/docs/Web"><span property="name">References</span></a><meta property="position" content="1"></li><li property="itemListElement" typeof="ListItem"><a class="breadcrumb" property="item" typeof="WebPage" href="../../API.html"><span property="name">Web APIs</span></a><meta property="position" content="2"></li><li property="itemListElement" typeof="ListItem"><a class="breadcrumb" property="item" typeof="WebPage" href="../WebXR_Device_API.html"><span property="name">WebXR Device API</span></a><meta property="position" content="3"></li><li property="itemListElement" typeof="ListItem"><a class="breadcrumb-current-page" property="item" typeof="WebPage" href="Fundamentals.html"><span property="name">Fundamentals of WebXR</span></a><meta property="position" content="4"></li></ol></nav><div class="article-actions"><button type="button" class="button action has-icon article-actions-toggle" aria-label="Article actions"><span class="button-wrap"><span class="icon icon-ellipses "></span><span class="article-actions-dialog-heading">Article Actions</span></span></button><ul class="article-actions-entries"><li class="article-actions-entry"><div class="languages-switcher-menu open-on-focus-within"><button id="languages-switcher-button" type="button" class="button action small has-icon languages-switcher-menu" aria-haspopup="menu"><span class="button-wrap"><span class="icon icon-language "></span>English (US)</span></button></div></li></ul></div></div></div></div><div class="main-wrapper"><aside id="sidebar-quicklinks" class="sidebar"><button type="button" class="button action backdrop" aria-label="Collapse sidebar"><span class="button-wrap"></span></button><nav aria-label="Related Topics" class="sidebar-inner"><div class="in-nav-toc"><div class="document-toc-container"><section class="document-toc"><header><h2 class="document-toc-heading">In this article</h2></header><ul class="document-toc-list"><li class="document-toc-item "><a class="document-toc-link" href="#what_webxr_is_and_isnt">What WebXR is and isn't</a></li><li class="document-toc-item "><a class="document-toc-link" href="#basic_concepts">Basic concepts</a></li><li class="document-toc-item "><a class="document-toc-link" href="#types_of_webxr_hardware">Types of WebXR hardware</a></li><li class="document-toc-item "><a class="document-toc-link" href="#important_health_and_safety_reminders">Important health and safety reminders</a></li><li class="document-toc-item "><a class="document-toc-link" href="#the_role_of_frameworks">The role of frameworks</a></li><li class="document-toc-item "><a class="document-toc-link" href="#next_steps">Next steps</a></li></ul></section></div></div><div><ol><li><strong><a href="../WebXR_Device_API.html">WebXR Device API</a></strong></li><li class="toggle"><details open=""><summary>Guides</summary><ol><li><em><a href="Fundamentals.html" aria-current="page">Fundamentals of WebXR</a></em></li></ol></details></li><li class="toggle"><details open=""><summary>Interfaces</summary><ol><li><a href="../XRAnchor.html"><code>XRAnchor</code></a></li><li><a href="../XRBoundedReferenceSpace.html"><code>XRBoundedReferenceSpace</code></a></li><li><a href="../XRCPUDepthInformation.html"><code>XRCPUDepthInformation</code></a></li><li><a href="../XRDepthInformation.html"><code>XRDepthInformation</code></a></li><li><a href="../XRFrame.html"><code>XRFrame</code></a></li><li><a href="../XRInputSource.html"><code>XRInputSource</code></a></li><li><a href="../XRInputSourceArray.html"><code>XRInputSourceArray</code></a></li><li><a href="../XRInputSourceEvent.html"><code>XRInputSourceEvent</code></a></li><li><a href="../XRInputSourcesChangeEvent.html"><code>XRInputSourcesChangeEvent</code></a></li><li><a href="../XRPose.html"><code>XRPose</code></a></li><li><a href="../XRReferenceSpace.html"><code>XRReferenceSpace</code></a></li><li><a href="../XRReferenceSpaceEvent.html"><code>XRReferenceSpaceEvent</code></a></li><li><a href="../XRRenderState.html"><code>XRRenderState</code></a></li><li><a href="../XRRigidTransform.html"><code>XRRigidTransform</code></a></li><li><a href="../XRSession.html"><code>XRSession</code></a></li><li><a href="../XRSessionEvent.html"><code>XRSessionEvent</code></a></li><li><a href="../XRSpace.html"><code>XRSpace</code></a></li><li><a href="../XRSystem.html"><code>XRSystem</code></a></li><li><a href="../XRView.html"><code>XRView</code></a></li><li><a href="../XRViewerPose.html"><code>XRViewerPose</code></a></li><li><a href="../XRViewport.html"><code>XRViewport</code></a></li><li><a href="../XRWebGLBinding.html"><code>XRWebGLBinding</code></a></li><li><a href="../XRWebGLDepthInformation.html"><code>XRWebGLDepthInformation</code></a></li><li><a href="../XRWebGLLayer.html"><code>XRWebGLLayer</code></a></li></ol></details></li><li class="toggle"><details open=""><summary>Properties</summary><ol><li><a href="../Navigator/xr.html"><code>Navigator.xr</code></a></li></ol></details></li><li class="toggle"><details open=""><summary>Methods</summary><ol><li><a href="../WebGLRenderingContext/makeXRCompatible.html"><code>WebGLRenderingContext.makeXRCompatible()</code></a></li></ol></details></li><li class="toggle"><details open=""><summary>Events</summary><ol><li><a href="../XRReferenceSpace/reset_event.html"><code>XRReferenceSpace</code>: <code>reset</code></a></li><li><a href="../XRSession/end_event.html"><code>XRSession</code>: <code>end</code></a></li><li><a href="../XRSession/inputsourceschange_event.html"><code>XRSession</code>: <code>inputsourceschange</code></a></li><li><a href="../XRSession/select_event.html"><code>XRSession</code>: <code>select</code></a></li><li><a href="../XRSession/selectend_event.html"><code>XRSession</code>: <code>selectend</code></a></li><li><a href="../XRSession/selectstart_event.html"><code>XRSession</code>: <code>selectstart</code></a></li><li><a href="../XRSession/visibilitychange_event.html"><code>XRSession</code>: <code>visibilitychange</code></a></li><li><a href="../XRSystem/devicechange_event.html"><code>XRSystem</code>: <code>devicechange</code></a></li></ol></details></li></ol></div></nav></aside><aside class="toc"><nav><div class="document-toc-container"><section class="document-toc"><header><h2 class="document-toc-heading">In this article</h2></header><ul class="document-toc-list"><li class="document-toc-item "><a class="document-toc-link" href="#what_webxr_is_and_isnt">What WebXR is and isn't</a></li><li class="document-toc-item "><a class="document-toc-link" href="#basic_concepts">Basic concepts</a></li><li class="document-toc-item "><a class="document-toc-link" href="#types_of_webxr_hardware">Types of WebXR hardware</a></li><li class="document-toc-item "><a class="document-toc-link" href="#important_health_and_safety_reminders">Important health and safety reminders</a></li><li class="document-toc-item "><a class="document-toc-link" href="#the_role_of_frameworks">The role of frameworks</a></li><li class="document-toc-item "><a class="document-toc-link" href="#next_steps">Next steps</a></li></ul></section></div></nav></aside><main id="content" class="main-content  "><article class="main-page-content" lang="en-US"><h1>Fundamentals of WebXR</h1><div class="section-content"><p>WebXR, with the <a href="../WebXR_Device_API.html">WebXR Device API</a> at its core, provides the functionality needed to bring both augmented and virtual reality (AR and VR) to the web. Together, these technologies are referred to as <strong>mixed reality (MR)</strong> or <strong>cross reality (XR)</strong>. Mixed reality is a large and complex subject, with much to learn and many other APIs to bring together to create an engaging experience for users.</p>
<p>This guide provides an overview of what WebXR is and how it works, as well as the preliminary foundation needed to start developing augmented and virtual reality experiences for the web.</p></div><section aria-labelledby="what_webxr_is_and_isnt"><a class="dashAnchor" name="//apple_ref/Section/What%20WebXR%20is%20and%20isn%27t"></a><h2 id="what_webxr_is_and_isnt"><a href="#what_webxr_is_and_isnt">What WebXR is and isn't</a></h2><div class="section-content"><p>WebXR is an API for web content and apps to use to interface with mixed reality hardware such as VR headsets and glasses with integrated augmented reality features. This includes both managing the process of rendering the views needed to simulate the 3D experience and the ability to sense the movement of the headset (or other motion-sensing gear) and provide the needed data to update the imagery shown to the user.</p>
<p>WebXR additionally provides support for accepting inputs from control devices such as handheld VR controllers or specialized mixed reality gamepads.</p>
<p><em>WebXR is not a rendering technology and does not provide features for managing 3D data or rendering it to the display.</em> This is an important fact to keep in mind. While WebXR manages the timing, scheduling, and the various points of view relevant when drawing the scene, it does <em>not</em> know how to load and manage models, nor how to render and texture them, and so forth. That part is entirely up to you. Fortunately, WebGL and the various WebGL-based frameworks and libraries are available to make it much easier to deal with all of that.</p></div></section><section aria-labelledby="how_is_webxr_different_from_webvr"><h3 id="how_is_webxr_different_from_webvr"><a href="#how_is_webxr_different_from_webvr">How is WebXR different from WebVR?</a></h3><div class="section-content"><p>WebVR was considered an experimental API designed to help specification writers determine the best approaches for creating a virtual reality API on the Web. Browser implementors added WebVR support to browsers, allowing web developers to experiment. But soon it became clear that to finish an API for virtual reality on the web, it would make more sense to start a new specification than to try to "fix" WebVR.</p>
<p>That led to the birth of WebXR. The fundamental difference is that WebXR supports not only virtual reality, but also augmented reality, which blends virtual objects with the user's ambient environment.</p>
<p>Another key difference is that WebXR has integrated support for the advanced <a href="Inputs.html">input controllers</a> that are used with most mixed reality headsets, while WebVR relied on the <a href="../Gamepad_API.html">Gamepad API</a> to support the controllers. In WebXR, the primary select and squeeze actions are directly supported using events, while other controls are available through a special WebXR-specific implementation of the <a href="../Gamepad.html"><code>Gamepad</code></a> object.</p></div></section><section aria-labelledby="basic_concepts"><a class="dashAnchor" name="//apple_ref/Section/Basic%20concepts"></a><h2 id="basic_concepts"><a href="#basic_concepts">Basic concepts</a></h2><div class="section-content"><p>Before getting into too much detail, let's consider some basic concepts that you need to know before you learn how to develop XR code.</p></div></section><section aria-labelledby="field_of_view"><h3 id="field_of_view"><a href="#field_of_view">Field of view</a></h3><div class="section-content"><p>The term <strong>field of view</strong> (<strong>FOV</strong>) is one which applies to any visual technology, from old film cameras to modern digital video cameras, including the cameras in computers and mobile devices.</p>
<p>
  <img src="Fundamentals/binocular-vision.svg" alt="Diagram showing binocular vision." width="550" height="720" loading="lazy">
</p>
<h4 id="what_is_field_of_view">What is field of view?</h4>
<p>The field of view is the extent to which you are able to see the environment. The width of the field of view, specified in either degrees or radians, is measured as the angle defining the arc from the far left edge of your field of view to the far right edge.</p>
<p>A human eye is able to take in a FOV of around 135°. Assuming a person has two healthy eyes, the total field of view ends up being about 200° to 220° wide. Why is the FOV wider with two eyes, but not double the single-eye FOV? It's because the two eyes' FOVs overlap a lot. That overlap gives us depth perception, which is around 115° wide. Outside the overlap area, our vision falls back to monocular.</p>
<p>The drawing shown here demonstrates the concept of FOV: blue wedge for the left eye, red wedge for the right eye. The light brown overlapping area is where the viewer has binocular vision and can perceive depth. If you look carefully, you'll see that each eye sees the die slightly differently, and the combined view blends the two into a 3D shape.</p>
<p>Generally, applications only define and manage the horizontal FOV. For more details, see <a href="Rendering.html#the_optics_of_3d">The optics of 3D</a>.</p>
<h4 id="field_of_view_and_mixed_reality_devices">Field of view and mixed reality devices</h4>
<p>To achieve a wide enough field of view that the user's eyes are tricked into believing that the virtual world completely surrounds them, the FOV needs to at least approach the width of the binocular vision area. Basic headsets typically start around 90° or so, while the best headsets generally have a field of view of around 150°. Because the FOV is a matter of the size of the lenses and how close they are to the user's eyes, there are limitations on how wide the FOV can get without installing lenses into the user's eyeballs.</p>
<p>A wide FOV can substantially improve the user's sense of immersion. However, increasing the FOV can also increase the weight and cost of the headset.</p></div></section><section aria-labelledby="degrees_of_freedom"><h3 id="degrees_of_freedom"><a href="#degrees_of_freedom">Degrees of freedom</a></h3><div class="section-content"><p>The term <strong>degrees of freedom</strong> is an indication of how much freedom of movement the user has within the virtual world. This is directly related to how many types of movement the WebXR hardware configuration is capable of recognizing and reproducing into the virtual scene.</p>
<p>
  <strong>Figure: Diagram showing the movements possible with 3 degree of freedom hardware: yaw, roll, and pitch.</strong>
  <img src="Fundamentals/3-degrees-of-freedom-min.svg" alt="Diagram showing the movements possible with 3 degree of freedom hardware: yaw, roll, and pitch." width="918" height="918" loading="lazy">
</p>
<h4 id="freedom_of_rotational_movement">Freedom of rotational movement</h4>
<p>The first three degrees of freedom are <strong>rotational</strong>. The rotational degrees of freedom are:</p>
<ul>
  <li>Pitch: looking up and down</li>
  <li>Yaw: looking left and right</li>
  <li>Roll: tilting left and right</li>
</ul>
<p>In all of these cases, the viewer remains in the same location in space while pivoting on one or more of the three axes to alter the direction in which they're looking. A system with two degrees of freedom can sense when the user looks left and right or up and down, but can't report any other kind of movement.</p>
<p>A typical baseline headset offers three degrees of freedom, recognizing rotation around all three axes. This is often referred to by the shorthand <strong>3DoF</strong>.</p>
<h4 id="freedom_of_translational_movement">Freedom of translational movement</h4>
<p>The other three degrees of freedom are translational, providing the ability to sense movement through space: forward and backward, left and right, up and down. Support for all six degrees of freedom is referred to as <strong>6DoF</strong>.</p>
<p>
  <img src="Fundamentals/xr-translation-headset.png" alt="Diagram showing rotation around each of the three axes in a WebXR setting" width="640" height="500" loading="lazy">
</p>
<p>Some more advanced headsets provide at least minimal support for translational movement detection, but to capture more substantial movement through the space, external sensors are usually required, such as cameras (either using visible light or infrared).</p></div></section><section aria-labelledby="webxr_session_modes"><h3 id="webxr_session_modes"><a href="#webxr_session_modes">WebXR session modes</a></h3><div class="section-content"><p>WebXR offers support for both augmented reality (AR) and virtual reality (VR) sessions, using the same API. Which type of session you want to create is specified when creating the session. This is done by specifying the appropriate session mode string for the kind of session you want to create.</p>
<h4 id="virtual_reality">Virtual reality</h4>
<p>In a VR environment, the entire image is digitally created by your app or site, from foreground objects all the way to the background or skybox. Your frame drawing code will have to redraw every pixel of each view during each frame in order to avoid the potential of artifacts being left behind. Some platforms may provide previously-cleared frames to you, while others may optimize performance by not erasing the framebuffers in order to avoid having to touch each pixel twice per frame.</p>
<p>There are two VR session modes available in WebXR: <strong>inline</strong> and <strong>immersive</strong>. The former, specified by the session mode string <code>inline</code>, presents the rendered scene within the context of a document in a web browser, and doesn't require special XR hardware to view. The immersive session mode is indicated using the session mode <code>immersive-vr</code>. This session mode requires an XR device such as a headset, and replaces the entire world with the rendered scene using the displays shown to each of the user's eyes.</p>
<h4 id="augmented_reality">Augmented reality</h4>
<p>In augmented reality (AR), the user sees the imagery you render presented on top of the physical, real-world environment around them. Because AR is always an immersive experience, in which the scene is the entire world around the user (rather than being enclosed in a box on a screen), the only AR session mode is <code>immersive-ar</code>.</p>
<p>There are two basic types of AR device:</p>
<ul>
  <li>Devices which use cameras to capture the world in front of the user, render the WebXR content atop that image, then display the image on a screen. These devices include phones, which show the resulting scene on the device's screen in a 2D presentation, as well as goggles that use a pair of cameras, one for each eye, to capture the scene in stereo in order to retain the world's depth, with the WebXR scene then rendered for each eye with that eye's captured background in place.</li>
  <li>Devices which use transparent glasses to allow the user to see the world, while overlaying the rendered image atop the scene. The user is, thus, directly viewing the real world instead of a series of digital photos of it.</li>
</ul>
<p>Both types of device should be capable of also presenting VR sessions. WebXR doesn't generally care which type of device you're using, and the rendering process is almost exactly the same as for VR, except you don't erase the background or skybox before rendering each frame.</p></div></section><section aria-labelledby="types_of_webxr_hardware"><a class="dashAnchor" name="//apple_ref/Section/Types%20of%20WebXR%20hardware"></a><h2 id="types_of_webxr_hardware"><a href="#types_of_webxr_hardware">Types of WebXR hardware</a></h2><div class="section-content"><p>The simplest XR presentation involves rendering the scene directly to the user's screen, either in the context of a web document, or in full screen mode. This is most common when the user either doesn't have a dedicated XR device, or when the user is viewing the AR or VR app on a phone or other handheld device.</p>
<p>Simpler and lower-priced XR devices typically use an integrated computer or connect to a smartphone, essentially using the mobile CPU and GPU to run apps, render images, and display them to the user. Higher-powered solutions typically offload application execution and graphics processing to an external device such as a desktop computer, and are either tethered to the computer using a cable or use a wireless network to receive the imagery to display to the user.</p></div></section><section aria-labelledby="headsets"><h3 id="headsets"><a href="#headsets">Headsets</a></h3><div class="section-content"><p>Most immersive VR experiences take place using goggles or a headset of some kind. A VR headset is worn on the head, with a strap that goes behind the head to fasten it in place, and one or two displays whose screens are focused into the eyes using lenses. By presenting a slightly different image to each eye, the illusion of depth is created, giving the user a simulated 3D experience.</p>
<p>
  <img src="Fundamentals/publicdomain-virtual_reality_headset.svg" alt="Drawing of a standard VR headset" width="810" height="607" loading="lazy">
</p>
<p>The vast majority of headsets use a single display whose frame is divided in half, with one half focused onto each of the user's eyes. For example, if a headset uses a 2560x1440 screen, with the left half being used for the left eye's view and the right half for the right eye's view, the framebuffer is used like this:</p>
<p>
  <img src="Fundamentals/twoviewsoneframebuffer.svg" alt="Diagram showing how a framebuffer is divided between two eyes' viewpoints" width="751" height="504" loading="lazy">
</p>
<p>The simplest headsets have no integrated sensors, and focus each half of the screen into the corresponding eye. A common example of this is <a href="https://arvr.google.com/cardboard/" class="external" target="_blank">Google Cardboard</a>, a type of headset first created by Google which can be cheaply created using cardboard or other inexpensive materials. These devices often work by snapping your phone into the headset so that its screen and onboard graphics processor can be used to render and display the XR scene.</p>
<p>More advanced headsets have integrated displays and are strapped to the head using an elastic or strap or a strap with Velcro closure. These headsets may include integrated speakers and microphone, and/or connectors to attach external ones. Additionally, these headsets may have various sensors for detecting when the headset moves through space. The types and number of sensors included will determine how many <a href="#degrees_of_freedom">degrees of freedom</a> the user has.</p></div></section><section aria-labelledby="goggles_and_glasses"><h3 id="goggles_and_glasses"><a href="#goggles_and_glasses">Goggles and glasses</a></h3><div class="section-content"><p>XR goggles are similar to headsets in that they involve the placing of graphics display surfaces in front of the eyes in order to render the views of a scene needed to simulate the depth of the simulated scene.</p>
<p>The difference is that the goggles pass through the real world, overlaying the rendered image on top of the user's physical environment. This is done without digitally reproducing the world, as would be necessary with a full headset. Instead, the display surface is transparent, and if not displaying anything is essentially identical to wearing regular eyeglasses. When objects are drawn, they are drawn onto the goggles' lenses, either partially or completely blocking the physical environment from being seen through the obscured portion of the lens.</p></div></section><section aria-labelledby="caves"><h3 id="caves"><a href="#caves">CAVEs</a></h3><div class="section-content"><p>A <strong>Cave Automated Virtual Environment</strong> (<strong>CAVE</strong>) is an immersive VR environment in which the scene is projected or otherwise displayed on the walls (as well as possibly the ceiling and/or floor), thus completely surrounding the user with the simulation and allowing them to be immersed in the scene. The user wears 3D glasses that both add the 3D effect to the projected image, but provide a means for the system to render foreground objects into the world.</p>
<p>The user's activity may be monitored using motion sensors that are worn or held by the user, or, increasingly commonly, using infrared cameras that detect the user's movements. Speakers placed around the chamber provide immersive sound as well.</p>
<p>These are not common among everyday users; they're mostly either experimental, used for demonstration purposes, or used by larger organizations. One drawback is that the CAVE can't simulate anything closer than the wall.</p></div></section><section aria-labelledby="important_health_and_safety_reminders"><a class="dashAnchor" name="//apple_ref/Section/Important%20health%20and%20safety%20reminders"></a><h2 id="important_health_and_safety_reminders"><a href="#important_health_and_safety_reminders">Important health and safety reminders</a></h2><div class="section-content"><p>Because the entire act of creating a virtual 3D world is, in essence, a trick which takes advantage of our understanding of how eyes collect light and how the brain interprets the collected data, it is important to keep in mind that as such, software designers and developers have a responsibility to be even more careful than usual to ensure that the results are correct.</p></div></section><section aria-labelledby="virtual_reality_sickness"><h3 id="virtual_reality_sickness"><a href="#virtual_reality_sickness">Virtual reality sickness</a></h3><div class="section-content"><p><strong><a href="https://en.wikipedia.org/wiki/Virtual_reality_sickness" class="external" target="_blank">Virtual reality sickness</a></strong> is a condition in which a person experiencing virtual reality feels discomfort, disorientation, or even serious nausea during and sometimes for a short time after the experience.</p>
<p>There are a number of theories surrounding exactly what about virtual reality causes some people to feel uncomfortable or sick, most of which focusing on the idea that even subtle differences between what the brain thinks should be happening and what is being seen can cause these symptoms.</p>
<p>Defects, misalignments, or distortion can confuse the eyes and the brain, resulting in anything from aching eyes or headache to in some cases vertigo, dizziness, or potentially severe nausea. It's also important to be alert for anything you may display that may have the potential to trigger seizures, given the all-encompassing nature of a headset; the user may not be able to quickly look away from the imagery you're presenting if it's causing distress.</p></div></section><section aria-labelledby="physical_risks"><h3 id="physical_risks"><a href="#physical_risks">Physical risks</a></h3><div class="section-content"><p>Another potential issue with immersive virtual reality is the user colliding with physical obstacles if they're moving around their room while wearing a headset. Unless they're in a safe environment, it's important to provide cues to restrict their movement, such as by simulating a space that is known to be safe within their physical environment.</p>
<p>If the user's headset is tethered to a device, it's a good idea to try to ensure that the user isn't prompted or tempted to move in such a way that they pull or yank on the headset cord, which could not only cause injury, but could cause significant damage to the user's headset or device (whether it's a phone or a computer).</p>
<p>If you have any content that may be of risk to any users, you should provide a warning message. Likewise, it's worth reminding users to remain seated if possible, and to be cautious about moving around while wearing a headset if the experience is fully-immersive virtual reality. It's always better to be safe than sorry!</p></div></section><section aria-labelledby="the_role_of_frameworks"><a class="dashAnchor" name="//apple_ref/Section/The%20role%20of%20frameworks"></a><h2 id="the_role_of_frameworks"><a href="#the_role_of_frameworks">The role of frameworks</a></h2><div class="section-content"><p>Because 3D graphics—and mixed reality in particular—involve a lot of often intricate math, data management, and other complex tasks, it's unlikely that you'll directly use WebGL to render your scene in most cases. Instead, you'll probably do most of your work making use of one of the frameworks or libraries that are built atop WebGL to make it more convenient to use.</p>
<p>A particular benefit to using a framework rather than directly using the WebGL API is that libraries tend to implement virtual camera functionality. OpenGL (and thus WebGL by extension) does not directly offer a camera view, using a library that simulates one on your behalf can make your job much, much easier, especially when building code that allows free movement through your virtual world.</p>
<p>Since <a href="../WebGL_API.html">WebGL</a> is used for rendering the 3D world into the WebXR session, you should first be familiar with WebGL's general usage, and with the basics of 3D graphics in general.</p></div></section><section aria-labelledby="general-purpose_3d_frameworks"><h3 id="general-purpose_3d_frameworks"><a href="#general-purpose_3d_frameworks">General-purpose 3D frameworks</a></h3><div class="section-content"><p>These frameworks are good for general-purpose programming as well as for game development when you want to do the logic yourself. They're designed for creating and animating 3D scenes regardless of context.</p>
<ul>
  <li><a href="https://aframe.io/" class="external" target="_blank">A-Frame</a> (specifically designed for creating WebXR-based apps)</li>
  <li><a href="https://www.babylonjs.com/" class="external" target="_blank">Babylon.js</a></li>
  <li><a href="https://threejs.org/" class="external" target="_blank">Three.js</a></li>
</ul></div></section><section aria-labelledby="game_toolkits"><h3 id="game_toolkits"><a href="#game_toolkits">Game toolkits</a></h3><div class="section-content"><p>The game toolkits are designed for game developers and often include gaming-specific features such as physics models, input control systems, asset management, 3D sound playback, and the like.</p>
<ul>
  <li><a href="https://playcanvas.com/" class="external" target="_blank">PlayCanvas</a></li>
</ul></div></section><section aria-labelledby="next_steps"><a class="dashAnchor" name="//apple_ref/Section/Next%20steps"></a><h2 id="next_steps"><a href="#next_steps">Next steps</a></h2><div class="section-content"><p>With these basic facts in hand, you're ready to take those next steps into the world of mixed reality. The following articles can help.</p>
<ul>
  <li><a href="Lifecycle.html">WebXR application life cycle</a></li>
  <li><a href="Startup_and_shutdown.html">Starting up and shutting down a WebXR session</a></li>
  <li><a href="Movement_and_motion.html">Movement, orientation, and motion: A WebXR example</a></li>
</ul></div></section><aside class="metadata"><div class="metadata-content-container"><div id="on-github" class="on-github"><h3>Found a content problem with this page?</h3><ul><li>Edit the page <a href="https://github.com/mdn/content/edit/main/files/en-us/web/api/webxr_device_api/fundamentals/index.md" title="This will take you to GitHub, where you'll need to sign in first." target="_blank" rel="noopener noreferrer">on GitHub</a>.</li><li>Report the <a href="https://github.com/mdn/content/issues/new?template=page-report.yml&amp;mdn-url=https%3A%2F%2Fdeveloper.mozilla.org%2Fen-US%2Fdocs%2FWeb%2FAPI%2FWebXR_Device_API%2FFundamentals&amp;metadata=%3C%21--+Do+not+make+changes+below+this+line+--%3E%0A%3Cdetails%3E%0A%3Csummary%3EPage+report+details%3C%2Fsummary%3E%0A%0A*+Folder%3A+%60en-us%2Fweb%2Fapi%2Fwebxr_device_api%2Ffundamentals%60%0A*+MDN+URL%3A+https%3A%2F%2Fdeveloper.mozilla.org%2Fen-US%2Fdocs%2FWeb%2FAPI%2FWebXR_Device_API%2FFundamentals%0A*+GitHub+URL%3A+https%3A%2F%2Fgithub.com%2Fmdn%2Fcontent%2Fblob%2Fmain%2Ffiles%2Fen-us%2Fweb%2Fapi%2Fwebxr_device_api%2Ffundamentals%2Findex.md%0A*+Last+commit%3A+https%3A%2F%2Fgithub.com%2Fmdn%2Fcontent%2Fcommit%2F65cd9754ed95f116b641c68cad80f14ecf580b41%0A*+Document+last+modified%3A+2023-01-21T12%3A18%3A52.000Z%0A%0A%3C%2Fdetails%3E" title="This will take you to GitHub to file a new issue." target="_blank" rel="noopener noreferrer">content issue</a>.</li><li>View the source <a href="https://github.com/mdn/content/blob/main/files/en-us/web/api/webxr_device_api/fundamentals/index.md?plain=1" title="Folder: en-us/web/api/webxr_device_api/fundamentals (Opens in a new tab)" target="_blank" rel="noopener noreferrer">on GitHub</a>.</li></ul>Want to get more involved? Learn<!-- --> <a href="https://github.com/mdn/content/blob/main/CONTRIBUTING.md" title="This will take you to our contribution guidelines on GitHub." target="_blank" rel="noopener noreferrer">how to contribute</a>.</div><p class="last-modified-date">This page was last modified on<!-- --> <time datetime="2023-01-21T12:18:52.000Z">Jan 21, 2023</time> by<!-- --> <a href="Fundamentals/contributors.txt">MDN contributors</a>.</p></div></aside></article></main></div><footer id="nav-footer" class="page-footer"><div><a href="http://developer.mozilla.org/en-US/docs/Web/API/WebXR_Device_API/Fundamentals">Fundamentals of WebXR</a> by <a href="http://developer.mozilla.org/en-US/docs/Web/API/WebXR_Device_API/Fundamentals$history">Mozilla Contributors</a> is licensed under <a href="http://creativecommons.org/licenses/by-sa/2.5/">CC-BY-SA 2.5</a>.</div></footer></div></div><script type="application/json" id="hydration">{"doc":{"isMarkdown":true,"isTranslated":false,"isActive":true,"flaws":{},"title":"Fundamentals of WebXR","mdn_url":"/en-US/docs/Web/API/WebXR_Device_API/Fundamentals","locale":"en-US","native":"English (US)","sidebarHTML":"<ol><li><strong><a href=\"/en-US/docs/Web/API/WebXR_Device_API\">WebXR Device API</a></strong></li><li class=\"toggle\"><details open=\"\"><summary>Guides</summary><ol><li><em><a href=\"/en-US/docs/Web/API/WebXR_Device_API/Fundamentals\" aria-current=\"page\">Fundamentals of WebXR</a></em></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Interfaces</summary><ol><li><a href=\"/en-US/docs/Web/API/XRAnchor\"><code>XRAnchor</code></a></li><li><a href=\"/en-US/docs/Web/API/XRBoundedReferenceSpace\"><code>XRBoundedReferenceSpace</code></a></li><li><a href=\"/en-US/docs/Web/API/XRCPUDepthInformation\"><code>XRCPUDepthInformation</code></a></li><li><a href=\"/en-US/docs/Web/API/XRDepthInformation\"><code>XRDepthInformation</code></a></li><li><a href=\"/en-US/docs/Web/API/XRFrame\"><code>XRFrame</code></a></li><li><a href=\"/en-US/docs/Web/API/XRInputSource\"><code>XRInputSource</code></a></li><li><a href=\"/en-US/docs/Web/API/XRInputSourceArray\"><code>XRInputSourceArray</code></a></li><li><a href=\"/en-US/docs/Web/API/XRInputSourceEvent\"><code>XRInputSourceEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/XRInputSourcesChangeEvent\"><code>XRInputSourcesChangeEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/XRPose\"><code>XRPose</code></a></li><li><a href=\"/en-US/docs/Web/API/XRReferenceSpace\"><code>XRReferenceSpace</code></a></li><li><a href=\"/en-US/docs/Web/API/XRReferenceSpaceEvent\"><code>XRReferenceSpaceEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/XRRenderState\"><code>XRRenderState</code></a></li><li><a href=\"/en-US/docs/Web/API/XRRigidTransform\"><code>XRRigidTransform</code></a></li><li><a href=\"/en-US/docs/Web/API/XRSession\"><code>XRSession</code></a></li><li><a href=\"/en-US/docs/Web/API/XRSessionEvent\"><code>XRSessionEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/XRSpace\"><code>XRSpace</code></a></li><li><a href=\"/en-US/docs/Web/API/XRSystem\"><code>XRSystem</code></a></li><li><a href=\"/en-US/docs/Web/API/XRView\"><code>XRView</code></a></li><li><a href=\"/en-US/docs/Web/API/XRViewerPose\"><code>XRViewerPose</code></a></li><li><a href=\"/en-US/docs/Web/API/XRViewport\"><code>XRViewport</code></a></li><li><a href=\"/en-US/docs/Web/API/XRWebGLBinding\"><code>XRWebGLBinding</code></a></li><li><a href=\"/en-US/docs/Web/API/XRWebGLDepthInformation\"><code>XRWebGLDepthInformation</code></a></li><li><a href=\"/en-US/docs/Web/API/XRWebGLLayer\"><code>XRWebGLLayer</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Properties</summary><ol><li><a href=\"/en-US/docs/Web/API/Navigator/xr\"><code>Navigator.xr</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Methods</summary><ol><li><a href=\"/en-US/docs/Web/API/WebGLRenderingContext/makeXRCompatible\"><code>WebGLRenderingContext.makeXRCompatible()</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Events</summary><ol><li><a href=\"/en-US/docs/Web/API/XRReferenceSpace/reset_event\"><code>XRReferenceSpace</code>: <code>reset</code></a></li><li><a href=\"/en-US/docs/Web/API/XRSession/end_event\"><code>XRSession</code>: <code>end</code></a></li><li><a href=\"/en-US/docs/Web/API/XRSession/inputsourceschange_event\"><code>XRSession</code>: <code>inputsourceschange</code></a></li><li><a href=\"/en-US/docs/Web/API/XRSession/select_event\"><code>XRSession</code>: <code>select</code></a></li><li><a href=\"/en-US/docs/Web/API/XRSession/selectend_event\"><code>XRSession</code>: <code>selectend</code></a></li><li><a href=\"/en-US/docs/Web/API/XRSession/selectstart_event\"><code>XRSession</code>: <code>selectstart</code></a></li><li><a href=\"/en-US/docs/Web/API/XRSession/visibilitychange_event\"><code>XRSession</code>: <code>visibilitychange</code></a></li><li><a href=\"/en-US/docs/Web/API/XRSystem/devicechange_event\"><code>XRSystem</code>: <code>devicechange</code></a></li></ol></details></li></ol>","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<p>WebXR, with the <a href=\"/en-US/docs/Web/API/WebXR_Device_API\">WebXR Device API</a> at its core, provides the functionality needed to bring both augmented and virtual reality (AR and VR) to the web. Together, these technologies are referred to as <strong>mixed reality (MR)</strong> or <strong>cross reality (XR)</strong>. Mixed reality is a large and complex subject, with much to learn and many other APIs to bring together to create an engaging experience for users.</p>\n<p>This guide provides an overview of what WebXR is and how it works, as well as the preliminary foundation needed to start developing augmented and virtual reality experiences for the web.</p>"}},{"type":"prose","value":{"id":"what_webxr_is_and_isnt","title":"What WebXR is and isn't","isH3":false,"content":"<p>WebXR is an API for web content and apps to use to interface with mixed reality hardware such as VR headsets and glasses with integrated augmented reality features. This includes both managing the process of rendering the views needed to simulate the 3D experience and the ability to sense the movement of the headset (or other motion-sensing gear) and provide the needed data to update the imagery shown to the user.</p>\n<p>WebXR additionally provides support for accepting inputs from control devices such as handheld VR controllers or specialized mixed reality gamepads.</p>\n<p><em>WebXR is not a rendering technology and does not provide features for managing 3D data or rendering it to the display.</em> This is an important fact to keep in mind. While WebXR manages the timing, scheduling, and the various points of view relevant when drawing the scene, it does <em>not</em> know how to load and manage models, nor how to render and texture them, and so forth. That part is entirely up to you. Fortunately, WebGL and the various WebGL-based frameworks and libraries are available to make it much easier to deal with all of that.</p>"}},{"type":"prose","value":{"id":"how_is_webxr_different_from_webvr","title":"How is WebXR different from WebVR?","isH3":true,"content":"<p>WebVR was considered an experimental API designed to help specification writers determine the best approaches for creating a virtual reality API on the Web. Browser implementors added WebVR support to browsers, allowing web developers to experiment. But soon it became clear that to finish an API for virtual reality on the web, it would make more sense to start a new specification than to try to \"fix\" WebVR.</p>\n<p>That led to the birth of WebXR. The fundamental difference is that WebXR supports not only virtual reality, but also augmented reality, which blends virtual objects with the user's ambient environment.</p>\n<p>Another key difference is that WebXR has integrated support for the advanced <a href=\"/en-US/docs/Web/API/WebXR_Device_API/Inputs\">input controllers</a> that are used with most mixed reality headsets, while WebVR relied on the <a href=\"/en-US/docs/Web/API/Gamepad_API\">Gamepad API</a> to support the controllers. In WebXR, the primary select and squeeze actions are directly supported using events, while other controls are available through a special WebXR-specific implementation of the <a href=\"/en-US/docs/Web/API/Gamepad\"><code>Gamepad</code></a> object.</p>"}},{"type":"prose","value":{"id":"basic_concepts","title":"Basic concepts","isH3":false,"content":"<p>Before getting into too much detail, let's consider some basic concepts that you need to know before you learn how to develop XR code.</p>"}},{"type":"prose","value":{"id":"field_of_view","title":"Field of view","isH3":true,"content":"<p>The term <strong>field of view</strong> (<strong>FOV</strong>) is one which applies to any visual technology, from old film cameras to modern digital video cameras, including the cameras in computers and mobile devices.</p>\n<p>\n  <img src=\"/en-US/docs/Web/API/WebXR_Device_API/Fundamentals/binocular-vision.svg\" alt=\"Diagram showing binocular vision.\" width=\"550\" height=\"720\" loading=\"lazy\">\n</p>\n<h4 id=\"what_is_field_of_view\">What is field of view?</h4>\n<p>The field of view is the extent to which you are able to see the environment. The width of the field of view, specified in either degrees or radians, is measured as the angle defining the arc from the far left edge of your field of view to the far right edge.</p>\n<p>A human eye is able to take in a FOV of around 135°. Assuming a person has two healthy eyes, the total field of view ends up being about 200° to 220° wide. Why is the FOV wider with two eyes, but not double the single-eye FOV? It's because the two eyes' FOVs overlap a lot. That overlap gives us depth perception, which is around 115° wide. Outside the overlap area, our vision falls back to monocular.</p>\n<p>The drawing shown here demonstrates the concept of FOV: blue wedge for the left eye, red wedge for the right eye. The light brown overlapping area is where the viewer has binocular vision and can perceive depth. If you look carefully, you'll see that each eye sees the die slightly differently, and the combined view blends the two into a 3D shape.</p>\n<p>Generally, applications only define and manage the horizontal FOV. For more details, see <a href=\"/en-US/docs/Web/API/WebXR_Device_API/Rendering#the_optics_of_3d\">The optics of 3D</a>.</p>\n<h4 id=\"field_of_view_and_mixed_reality_devices\">Field of view and mixed reality devices</h4>\n<p>To achieve a wide enough field of view that the user's eyes are tricked into believing that the virtual world completely surrounds them, the FOV needs to at least approach the width of the binocular vision area. Basic headsets typically start around 90° or so, while the best headsets generally have a field of view of around 150°. Because the FOV is a matter of the size of the lenses and how close they are to the user's eyes, there are limitations on how wide the FOV can get without installing lenses into the user's eyeballs.</p>\n<p>A wide FOV can substantially improve the user's sense of immersion. However, increasing the FOV can also increase the weight and cost of the headset.</p>"}},{"type":"prose","value":{"id":"degrees_of_freedom","title":"Degrees of freedom","isH3":true,"content":"<p>The term <strong>degrees of freedom</strong> is an indication of how much freedom of movement the user has within the virtual world. This is directly related to how many types of movement the WebXR hardware configuration is capable of recognizing and reproducing into the virtual scene.</p>\n<p>\n  <strong>Figure: Diagram showing the movements possible with 3 degree of freedom hardware: yaw, roll, and pitch.</strong>\n  <img src=\"/en-US/docs/Web/API/WebXR_Device_API/Fundamentals/3-degrees-of-freedom-min.svg\" alt=\"Diagram showing the movements possible with 3 degree of freedom hardware: yaw, roll, and pitch.\" width=\"918\" height=\"918\" loading=\"lazy\">\n</p>\n<h4 id=\"freedom_of_rotational_movement\">Freedom of rotational movement</h4>\n<p>The first three degrees of freedom are <strong>rotational</strong>. The rotational degrees of freedom are:</p>\n<ul>\n  <li>Pitch: looking up and down</li>\n  <li>Yaw: looking left and right</li>\n  <li>Roll: tilting left and right</li>\n</ul>\n<p>In all of these cases, the viewer remains in the same location in space while pivoting on one or more of the three axes to alter the direction in which they're looking. A system with two degrees of freedom can sense when the user looks left and right or up and down, but can't report any other kind of movement.</p>\n<p>A typical baseline headset offers three degrees of freedom, recognizing rotation around all three axes. This is often referred to by the shorthand <strong>3DoF</strong>.</p>\n<h4 id=\"freedom_of_translational_movement\">Freedom of translational movement</h4>\n<p>The other three degrees of freedom are translational, providing the ability to sense movement through space: forward and backward, left and right, up and down. Support for all six degrees of freedom is referred to as <strong>6DoF</strong>.</p>\n<p>\n  <img src=\"/en-US/docs/Web/API/WebXR_Device_API/Fundamentals/xr-translation-headset.png\" alt=\"Diagram showing rotation around each of the three axes in a WebXR setting\" width=\"640\" height=\"500\" loading=\"lazy\">\n</p>\n<p>Some more advanced headsets provide at least minimal support for translational movement detection, but to capture more substantial movement through the space, external sensors are usually required, such as cameras (either using visible light or infrared).</p>"}},{"type":"prose","value":{"id":"webxr_session_modes","title":"WebXR session modes","isH3":true,"content":"<p>WebXR offers support for both augmented reality (AR) and virtual reality (VR) sessions, using the same API. Which type of session you want to create is specified when creating the session. This is done by specifying the appropriate session mode string for the kind of session you want to create.</p>\n<h4 id=\"virtual_reality\">Virtual reality</h4>\n<p>In a VR environment, the entire image is digitally created by your app or site, from foreground objects all the way to the background or skybox. Your frame drawing code will have to redraw every pixel of each view during each frame in order to avoid the potential of artifacts being left behind. Some platforms may provide previously-cleared frames to you, while others may optimize performance by not erasing the framebuffers in order to avoid having to touch each pixel twice per frame.</p>\n<p>There are two VR session modes available in WebXR: <strong>inline</strong> and <strong>immersive</strong>. The former, specified by the session mode string <code>inline</code>, presents the rendered scene within the context of a document in a web browser, and doesn't require special XR hardware to view. The immersive session mode is indicated using the session mode <code>immersive-vr</code>. This session mode requires an XR device such as a headset, and replaces the entire world with the rendered scene using the displays shown to each of the user's eyes.</p>\n<h4 id=\"augmented_reality\">Augmented reality</h4>\n<p>In augmented reality (AR), the user sees the imagery you render presented on top of the physical, real-world environment around them. Because AR is always an immersive experience, in which the scene is the entire world around the user (rather than being enclosed in a box on a screen), the only AR session mode is <code>immersive-ar</code>.</p>\n<p>There are two basic types of AR device:</p>\n<ul>\n  <li>Devices which use cameras to capture the world in front of the user, render the WebXR content atop that image, then display the image on a screen. These devices include phones, which show the resulting scene on the device's screen in a 2D presentation, as well as goggles that use a pair of cameras, one for each eye, to capture the scene in stereo in order to retain the world's depth, with the WebXR scene then rendered for each eye with that eye's captured background in place.</li>\n  <li>Devices which use transparent glasses to allow the user to see the world, while overlaying the rendered image atop the scene. The user is, thus, directly viewing the real world instead of a series of digital photos of it.</li>\n</ul>\n<p>Both types of device should be capable of also presenting VR sessions. WebXR doesn't generally care which type of device you're using, and the rendering process is almost exactly the same as for VR, except you don't erase the background or skybox before rendering each frame.</p>"}},{"type":"prose","value":{"id":"types_of_webxr_hardware","title":"Types of WebXR hardware","isH3":false,"content":"<p>The simplest XR presentation involves rendering the scene directly to the user's screen, either in the context of a web document, or in full screen mode. This is most common when the user either doesn't have a dedicated XR device, or when the user is viewing the AR or VR app on a phone or other handheld device.</p>\n<p>Simpler and lower-priced XR devices typically use an integrated computer or connect to a smartphone, essentially using the mobile CPU and GPU to run apps, render images, and display them to the user. Higher-powered solutions typically offload application execution and graphics processing to an external device such as a desktop computer, and are either tethered to the computer using a cable or use a wireless network to receive the imagery to display to the user.</p>"}},{"type":"prose","value":{"id":"headsets","title":"Headsets","isH3":true,"content":"<p>Most immersive VR experiences take place using goggles or a headset of some kind. A VR headset is worn on the head, with a strap that goes behind the head to fasten it in place, and one or two displays whose screens are focused into the eyes using lenses. By presenting a slightly different image to each eye, the illusion of depth is created, giving the user a simulated 3D experience.</p>\n<p>\n  <img src=\"/en-US/docs/Web/API/WebXR_Device_API/Fundamentals/publicdomain-virtual_reality_headset.svg\" alt=\"Drawing of a standard VR headset\" width=\"810\" height=\"607\" loading=\"lazy\">\n</p>\n<p>The vast majority of headsets use a single display whose frame is divided in half, with one half focused onto each of the user's eyes. For example, if a headset uses a 2560x1440 screen, with the left half being used for the left eye's view and the right half for the right eye's view, the framebuffer is used like this:</p>\n<p>\n  <img src=\"/en-US/docs/Web/API/WebXR_Device_API/Fundamentals/twoviewsoneframebuffer.svg\" alt=\"Diagram showing how a framebuffer is divided between two eyes' viewpoints\" width=\"751\" height=\"504\" loading=\"lazy\">\n</p>\n<p>The simplest headsets have no integrated sensors, and focus each half of the screen into the corresponding eye. A common example of this is <a href=\"https://arvr.google.com/cardboard/\" class=\"external\" target=\"_blank\">Google Cardboard</a>, a type of headset first created by Google which can be cheaply created using cardboard or other inexpensive materials. These devices often work by snapping your phone into the headset so that its screen and onboard graphics processor can be used to render and display the XR scene.</p>\n<p>More advanced headsets have integrated displays and are strapped to the head using an elastic or strap or a strap with Velcro closure. These headsets may include integrated speakers and microphone, and/or connectors to attach external ones. Additionally, these headsets may have various sensors for detecting when the headset moves through space. The types and number of sensors included will determine how many <a href=\"#degrees_of_freedom\">degrees of freedom</a> the user has.</p>"}},{"type":"prose","value":{"id":"goggles_and_glasses","title":"Goggles and glasses","isH3":true,"content":"<p>XR goggles are similar to headsets in that they involve the placing of graphics display surfaces in front of the eyes in order to render the views of a scene needed to simulate the depth of the simulated scene.</p>\n<p>The difference is that the goggles pass through the real world, overlaying the rendered image on top of the user's physical environment. This is done without digitally reproducing the world, as would be necessary with a full headset. Instead, the display surface is transparent, and if not displaying anything is essentially identical to wearing regular eyeglasses. When objects are drawn, they are drawn onto the goggles' lenses, either partially or completely blocking the physical environment from being seen through the obscured portion of the lens.</p>"}},{"type":"prose","value":{"id":"caves","title":"CAVEs","isH3":true,"content":"<p>A <strong>Cave Automated Virtual Environment</strong> (<strong>CAVE</strong>) is an immersive VR environment in which the scene is projected or otherwise displayed on the walls (as well as possibly the ceiling and/or floor), thus completely surrounding the user with the simulation and allowing them to be immersed in the scene. The user wears 3D glasses that both add the 3D effect to the projected image, but provide a means for the system to render foreground objects into the world.</p>\n<p>The user's activity may be monitored using motion sensors that are worn or held by the user, or, increasingly commonly, using infrared cameras that detect the user's movements. Speakers placed around the chamber provide immersive sound as well.</p>\n<p>These are not common among everyday users; they're mostly either experimental, used for demonstration purposes, or used by larger organizations. One drawback is that the CAVE can't simulate anything closer than the wall.</p>"}},{"type":"prose","value":{"id":"important_health_and_safety_reminders","title":"Important health and safety reminders","isH3":false,"content":"<p>Because the entire act of creating a virtual 3D world is, in essence, a trick which takes advantage of our understanding of how eyes collect light and how the brain interprets the collected data, it is important to keep in mind that as such, software designers and developers have a responsibility to be even more careful than usual to ensure that the results are correct.</p>"}},{"type":"prose","value":{"id":"virtual_reality_sickness","title":"Virtual reality sickness","isH3":true,"content":"<p><strong><a href=\"https://en.wikipedia.org/wiki/Virtual_reality_sickness\" class=\"external\" target=\"_blank\">Virtual reality sickness</a></strong> is a condition in which a person experiencing virtual reality feels discomfort, disorientation, or even serious nausea during and sometimes for a short time after the experience.</p>\n<p>There are a number of theories surrounding exactly what about virtual reality causes some people to feel uncomfortable or sick, most of which focusing on the idea that even subtle differences between what the brain thinks should be happening and what is being seen can cause these symptoms.</p>\n<p>Defects, misalignments, or distortion can confuse the eyes and the brain, resulting in anything from aching eyes or headache to in some cases vertigo, dizziness, or potentially severe nausea. It's also important to be alert for anything you may display that may have the potential to trigger seizures, given the all-encompassing nature of a headset; the user may not be able to quickly look away from the imagery you're presenting if it's causing distress.</p>"}},{"type":"prose","value":{"id":"physical_risks","title":"Physical risks","isH3":true,"content":"<p>Another potential issue with immersive virtual reality is the user colliding with physical obstacles if they're moving around their room while wearing a headset. Unless they're in a safe environment, it's important to provide cues to restrict their movement, such as by simulating a space that is known to be safe within their physical environment.</p>\n<p>If the user's headset is tethered to a device, it's a good idea to try to ensure that the user isn't prompted or tempted to move in such a way that they pull or yank on the headset cord, which could not only cause injury, but could cause significant damage to the user's headset or device (whether it's a phone or a computer).</p>\n<p>If you have any content that may be of risk to any users, you should provide a warning message. Likewise, it's worth reminding users to remain seated if possible, and to be cautious about moving around while wearing a headset if the experience is fully-immersive virtual reality. It's always better to be safe than sorry!</p>"}},{"type":"prose","value":{"id":"the_role_of_frameworks","title":"The role of frameworks","isH3":false,"content":"<p>Because 3D graphics—and mixed reality in particular—involve a lot of often intricate math, data management, and other complex tasks, it's unlikely that you'll directly use WebGL to render your scene in most cases. Instead, you'll probably do most of your work making use of one of the frameworks or libraries that are built atop WebGL to make it more convenient to use.</p>\n<p>A particular benefit to using a framework rather than directly using the WebGL API is that libraries tend to implement virtual camera functionality. OpenGL (and thus WebGL by extension) does not directly offer a camera view, using a library that simulates one on your behalf can make your job much, much easier, especially when building code that allows free movement through your virtual world.</p>\n<p>Since <a href=\"/en-US/docs/Web/API/WebGL_API\">WebGL</a> is used for rendering the 3D world into the WebXR session, you should first be familiar with WebGL's general usage, and with the basics of 3D graphics in general.</p>"}},{"type":"prose","value":{"id":"general-purpose_3d_frameworks","title":"General-purpose 3D frameworks","isH3":true,"content":"<p>These frameworks are good for general-purpose programming as well as for game development when you want to do the logic yourself. They're designed for creating and animating 3D scenes regardless of context.</p>\n<ul>\n  <li><a href=\"https://aframe.io/\" class=\"external\" target=\"_blank\">A-Frame</a> (specifically designed for creating WebXR-based apps)</li>\n  <li><a href=\"https://www.babylonjs.com/\" class=\"external\" target=\"_blank\">Babylon.js</a></li>\n  <li><a href=\"https://threejs.org/\" class=\"external\" target=\"_blank\">Three.js</a></li>\n</ul>"}},{"type":"prose","value":{"id":"game_toolkits","title":"Game toolkits","isH3":true,"content":"<p>The game toolkits are designed for game developers and often include gaming-specific features such as physics models, input control systems, asset management, 3D sound playback, and the like.</p>\n<ul>\n  <li><a href=\"https://playcanvas.com/\" class=\"external\" target=\"_blank\">PlayCanvas</a></li>\n</ul>"}},{"type":"prose","value":{"id":"next_steps","title":"Next steps","isH3":false,"content":"<p>With these basic facts in hand, you're ready to take those next steps into the world of mixed reality. The following articles can help.</p>\n<ul>\n  <li><a href=\"/en-US/docs/Web/API/WebXR_Device_API/Lifecycle\">WebXR application life cycle</a></li>\n  <li><a href=\"/en-US/docs/Web/API/WebXR_Device_API/Startup_and_shutdown\">Starting up and shutting down a WebXR session</a></li>\n  <li><a href=\"/en-US/docs/Web/API/WebXR_Device_API/Movement_and_motion\">Movement, orientation, and motion: A WebXR example</a></li>\n</ul>"}}],"toc":[{"text":"What WebXR is and isn't","id":"what_webxr_is_and_isnt"},{"text":"Basic concepts","id":"basic_concepts"},{"text":"Types of WebXR hardware","id":"types_of_webxr_hardware"},{"text":"Important health and safety reminders","id":"important_health_and_safety_reminders"},{"text":"The role of frameworks","id":"the_role_of_frameworks"},{"text":"Next steps","id":"next_steps"}],"summary":"WebXR, with the WebXR Device API at its core, provides the functionality needed to bring both augmented and virtual reality (AR and VR) to the web. Together, these technologies are referred to as mixed reality (MR) or cross reality (XR). Mixed reality is a large and complex subject, with much to learn and many other APIs to bring together to create an engaging experience for users.","popularity":0,"modified":"2023-01-21T12:18:52.000Z","other_translations":[{"title":"WebXR の基礎","locale":"ja","native":"日本語"}],"source":{"folder":"en-us/web/api/webxr_device_api/fundamentals","github_url":"https://github.com/mdn/content/blob/main/files/en-us/web/api/webxr_device_api/fundamentals/index.md","last_commit_url":"https://github.com/mdn/content/commit/65cd9754ed95f116b641c68cad80f14ecf580b41","filename":"index.md"},"short_title":"Fundamentals of WebXR","parents":[{"uri":"/en-US/docs/Web","title":"References"},{"uri":"/en-US/docs/Web/API","title":"Web APIs"},{"uri":"/en-US/docs/Web/API/WebXR_Device_API","title":"WebXR Device API"},{"uri":"/en-US/docs/Web/API/WebXR_Device_API/Fundamentals","title":"Fundamentals of WebXR"}],"pageTitle":"Fundamentals of WebXR - Web APIs | MDN","noIndexing":false}}</script>
<!-- Mirrored from developer.mozilla.org/en-US/docs/Web/API/WebXR_Device_API/Fundamentals by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 14 Feb 2023 04:50:14 GMT -->
</body></html>